{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a7df77",
   "metadata": {},
   "source": [
    "# Linear Models and Regularization Methods\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/intro-stat-learning/ISLP_labs/blob/v2.2/Ch06-varselect-lab.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/intro-stat-learning/ISLP_labs/v2.2?labpath=Ch06-varselect-lab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12a766",
   "metadata": {},
   "source": [
    "In this lab we implement many of the techniques discussed in this chapter.\n",
    "We import some of our libraries at this top\n",
    "level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59f6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c47d1",
   "metadata": {},
   "source": [
    "We again collect the new imports\n",
    "needed for this lab. Readers will also have to have installed `l0bnb` using `pip install l0bnb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb597cb-5ec5-4f75-9451-c1b62e3a29d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting l0bnb\n",
      "  Downloading l0bnb-1.0.0.tar.gz (79 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /Users/aidanlockwood/GitHub/MXN442-Codebase/mxn442_venv/lib/python3.12/site-packages (from l0bnb) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/aidanlockwood/GitHub/MXN442-Codebase/mxn442_venv/lib/python3.12/site-packages (from l0bnb) (1.16.1)\n",
      "Collecting numba>=0.53.1 (from l0bnb)\n",
      "  Downloading numba-0.61.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.53.1->l0bnb)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting numpy>=1.18.1 (from l0bnb)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp312-cp312-macosx_11_0_arm64.whl (26.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: l0bnb\n",
      "  Building wheel for l0bnb (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for l0bnb: filename=l0bnb-1.0.0-py3-none-any.whl size=22383 sha256=824bbbb76571e18caf4b4da47a01e3344db90339a2e211c3dc1b8c86460f259b\n",
      "  Stored in directory: /Users/aidanlockwood/Library/Caches/pip/wheels/0e/74/8b/8a39b657554150b98e1520971211118b5137e6a1873a85f66a\n",
      "Successfully built l0bnb\n",
      "Installing collected packages: numpy, llvmlite, numba, l0bnb\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.2\n",
      "    Uninstalling numpy-2.3.2:\n",
      "      Successfully uninstalled numpy-2.3.2\n",
      "Successfully installed l0bnb-1.0.0 llvmlite-0.44.0 numba-0.61.2 numpy-2.2.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install l0bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8440e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from ISLP.models import \\\n",
    "     (Stepwise,\n",
    "      sklearn_selected,\n",
    "      sklearn_selection_path)\n",
    "# from l0bnb import fit_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf09cb",
   "metadata": {},
   "source": [
    "## Subset Selection Methods\n",
    "Here we implement methods that reduce the number of parameters in a\n",
    "model by restricting the model to a subset of the input variables.\n",
    "\n",
    "### Forward Selection (Bonus practice, but run it to use some of the outputs for the next one)\n",
    " \n",
    "We will  apply the forward-selection approach to the  `Hitters` \n",
    "data.  We wish to predict a baseball player’s `Salary` on the\n",
    "basis of various statistics associated with performance in the\n",
    "previous year.\n",
    "\n",
    "First of all, we note that the `Salary` variable is missing for\n",
    "some of the players.  The `np.isnan()`  function can be used to\n",
    "identify the missing observations. It returns an array\n",
    "of the same shape as the input vector, with a `True` for any elements that\n",
    "are missing, and a `False` for non-missing elements.  The\n",
    "`sum()`  method can then be used to count all of the\n",
    "missing elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d45749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(59)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hitters = load_data('Hitters')\n",
    "np.isnan(Hitters['Salary']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25acaae1",
   "metadata": {},
   "source": [
    " We see that `Salary` is missing for 59 players. The\n",
    "`dropna()`  method of data frames removes all of the rows that have missing\n",
    "values in any variable (by default --- see  `Hitters.dropna?`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47262cbe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hitters = Hitters.dropna();\n",
    "Hitters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199f18e",
   "metadata": {},
   "source": [
    "We first choose the best model using forward selection based on $C_p$ (6.2). This score\n",
    "is not built in as a metric to `sklearn`. We therefore define a function to compute it ourselves, and use\n",
    "it as a scorer. By default, `sklearn` tries to maximize a score, hence\n",
    "  our scoring function  computes the negative $C_p$ statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096fe127",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Write the function \"nCP\" that get the residual variance sigma2, estimator, X and U, and returns Cp statistic. \n",
    "def nCp(sigma2, estimator, X, Y):\n",
    "    \"Negative Cp statistic\"\n",
    "    n, p = X.shape\n",
    "    Yhat = estimator.predict(X)\n",
    "    RSS = np.sum((Y - Yhat)**2)\n",
    "    return -(RSS + 2 * p * sigma2) / n "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e3ca3",
   "metadata": {},
   "source": [
    "We need to estimate the residual variance $\\sigma^2$, which is the first argument in our scoring function above.\n",
    "We will fit the biggest model, using all the variables, and estimate $\\sigma^2$ based on its MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b697d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = MS(Hitters.columns.drop('Salary')).fit(Hitters)\n",
    "Y = np.array(Hitters['Salary'])\n",
    "X = design.transform(Hitters)\n",
    "sigma2 = OLS(Y,X).fit().scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc283589",
   "metadata": {},
   "source": [
    "The function `sklearn_selected()` expects a scorer with just three arguments --- the last three in the definition of `nCp()` above. We use the function `partial()` first seen in Section 5.3.3 to freeze the first argument with our estimate of $\\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151b133",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "neg_Cp = partial(nCp, sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6993ae8",
   "metadata": {},
   "source": [
    "We can now use `neg_Cp()` as a scorer for model selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a744d",
   "metadata": {},
   "source": [
    "Along with a score we need to specify the search strategy. This is done through the object\n",
    "`Stepwise()`  in the `ISLP.models` package. The method `Stepwise.first_peak()`\n",
    "runs forward stepwise until any further additions to the model do not result\n",
    "in an improvement in the evaluation score. Similarly, the method `Stepwise.fixed_steps()`\n",
    "runs a fixed number of steps of stepwise search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab28d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = Stepwise.first_peak(design,\n",
    "                               direction='forward',\n",
    "                               max_terms=len(design.terms))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf946d2",
   "metadata": {},
   "source": [
    "We now fit a linear regression model with `Salary` as outcome using forward\n",
    "selection. To do so, we use the function `sklearn_selected()`  from the `ISLP.models` package. This takes\n",
    "a model from `statsmodels` along with a search strategy and selects a model with its\n",
    "`fit` method. Without specifying a `scoring` argument, the score defaults to MSE, and so all 19 variables will be\n",
    "selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8b345ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Assists',\n",
       " 'AtBat',\n",
       " 'CAtBat',\n",
       " 'CHits',\n",
       " 'CHmRun',\n",
       " 'CRBI',\n",
       " 'CRuns',\n",
       " 'CWalks',\n",
       " 'Division',\n",
       " 'Errors',\n",
       " 'Hits',\n",
       " 'HmRun',\n",
       " 'League',\n",
       " 'NewLeague',\n",
       " 'PutOuts',\n",
       " 'RBI',\n",
       " 'Runs',\n",
       " 'Walks',\n",
       " 'Years')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters_MSE = sklearn_selected(OLS,\n",
    "                               strategy)\n",
    "hitters_MSE.fit(Hitters, Y)\n",
    "hitters_MSE.selected_state_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a78607",
   "metadata": {},
   "source": [
    "Using `neg_Cp` results in a smaller model, as expected, with just 10 variables selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915cdff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Assists',\n",
       " 'AtBat',\n",
       " 'CAtBat',\n",
       " 'CRBI',\n",
       " 'CRuns',\n",
       " 'CWalks',\n",
       " 'Division',\n",
       " 'Hits',\n",
       " 'PutOuts',\n",
       " 'Walks')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters_Cp = sklearn_selected(OLS,\n",
    "                               strategy,\n",
    "                               scoring=neg_Cp)\n",
    "hitters_Cp.fit(Hitters, Y)\n",
    "hitters_Cp.selected_state_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d37f87",
   "metadata": {},
   "source": [
    "### Choosing Among Models Using the Validation Set Approach and Cross-Validation\n",
    " \n",
    "As an  alternative to using $C_p$, we might try cross-validation to select a model in forward selection. For this, we need a\n",
    "method that stores the full path of models found in forward selection, and allows predictions for each of these. This can be done with the `sklearn_selection_path()` \n",
    "estimator from `ISLP.models`. The function `cross_val_predict()` from `ISLP.models`\n",
    "computes the cross-validated predictions for each of the models\n",
    "along the path, which we can use to evaluate the cross-validated MSE\n",
    "along the path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769115d",
   "metadata": {},
   "source": [
    "Here we define a strategy that fits the full forward selection path.\n",
    "While there are various parameter choices for `sklearn_selection_path()`,\n",
    "we use the defaults here, which selects the model at each step based on the biggest reduction  in RSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33ae4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a strategy for forward selection as per above explanation for finding the best model\n",
    "\n",
    "strategy = Stepwise.fixed_steps(\n",
    "    design,\n",
    "    direction='forward', n_steps = 5)\n",
    "full_path = sklearn_selection_path(OLS, strategy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd4a2cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary  \\\n",
       "1      321   414     375      N        W      632       43      10   475.0   \n",
       "2      224   266     263      A        W      880       82      14   480.0   \n",
       "3      828   838     354      N        E      200       11       3   500.0   \n",
       "4       48    46      33      N        E      805       40       4    91.5   \n",
       "5      501   336     194      A        W      282      421      25   750.0   \n",
       "..     ...   ...     ...    ...      ...      ...      ...     ...     ...   \n",
       "317    379   311     138      N        E      325        9       3   700.0   \n",
       "318    897   451     875      A        E      313      381      20   875.0   \n",
       "319    217    93     146      A        W       37      113       7   385.0   \n",
       "320    470   420     332      A        E     1314      131      12   960.0   \n",
       "321    775   357     249      A        W      408        4       3  1000.0   \n",
       "\n",
       "    NewLeague  \n",
       "1           N  \n",
       "2           A  \n",
       "3           N  \n",
       "4           N  \n",
       "5           A  \n",
       "..        ...  \n",
       "317         N  \n",
       "318         A  \n",
       "319         A  \n",
       "320         A  \n",
       "321         A  \n",
       "\n",
       "[263 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f3fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397415c",
   "metadata": {},
   "source": [
    "We now fit the full forward-selection path on the `Hitters` data and compute the fitted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f05e1a81",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path.fit(Hitters, Y)\n",
    "Yhat_in = full_path.predict(Hitters)\n",
    "Yhat_in.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767af527",
   "metadata": {},
   "source": [
    "This gives us an array of fitted values --- 20 steps in all, including the fitted mean for the null model --- which we can use to evaluate\n",
    "in-sample MSE. As expected, the in-sample MSE improves each step we take,\n",
    "indicating we must use either the validation or cross-validation\n",
    "approach to select the number of steps. We fix the y-axis to range from\n",
    "50,000 to 250,000 to compare to the cross-validation and validation\n",
    "set MSE below, as well as other methods such as ridge regression, lasso and\n",
    "principal components regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b07ae72",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt8AAAK6CAYAAADhMzAtAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAcyxJREFUeJzt3QeYE9X79vFnF9il995RpCMdRBBFuoDSRMCCgAgKKKCAqBRFRUEEKYoVUKQrvVcRAVGQqqA0QalK723e6zn/d/JLdrOV3ZlN9vu5rmGTzElyUna5c3LmOSGWZVkCAAAAINGFJv5dAAAAAFCEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCEBGb6HDh0qVapUkQwZMkjOnDmlWbNmsmfPHp82DzzwgISEhPhsXbt29Wlz6NAhady4saRNm9bcTp8+feTGjRs+bdasWSMVK1aU8PBwKVq0qEycODFSf8aNGyeFCxeW1KlTS7Vq1WTTpk0++69cuSLdunWTbNmySfr06aVly5Zy/PjxBH1OAAAAkPQFZPj+/vvvTZjduHGjLF++XK5fvy7169eXixcv+rTr3LmzHD161LMNGzbMs+/mzZsmeF+7dk3Wr18vkyZNMsF64MCBnjYHDhwwbWrXri1bt26Vnj17yjPPPCNLly71tJk+fbr07t1bBg0aJFu2bJFy5cpJgwYN5MSJE542vXr1kvnz58vMmTNN348cOSItWrRI9OcJAAAASUuIZVmWBLiTJ0+akWsNtrVq1fKMfJcvX15GjRrl9zqLFy+WJk2amCCcK1cuc9n48eOlX79+5vbCwsLM6YULF8rOnTs912vTpo2cOXNGlixZYs7rSLeOwo8dO9acv3XrlhQoUEB69Oghr7zyipw9e1Zy5MghU6ZMkVatWpk2u3fvlpIlS8qGDRvknnvuSfTnBwAAAElDSgkCGnBV1qxZfS7/5ptvZPLkyZI7d25p2rSpDBgwwEwxURp8y5Yt6wneSkesn3vuOdm1a5dUqFDBtKlbt67PbWobHQFXOmq+efNm6d+/v2d/aGiouY5eV+l+HZn3vp0SJUpIwYIFowzfV69eNZtNA/2pU6fMtBWdPgMAAICkRcezz58/L3nz5jV5MGjDtwZTDcM1atSQMmXKeC5v166dFCpUyDwB27dvN6PYOi/8u+++M/uPHTvmE7yVfV73Rdfm3LlzcvnyZTl9+rSZvuKvjY5u27eho+iZM2eO1Ma+H39z2t94443beFYAAADghsOHD0v+/PmDN3zr3G+dFrJu3Tqfy5999lnPaR3hzpMnj9SpU0f27dsnd955pyRlOpKu88i9R/Z1pFxfzIwZM7raNwAAAESmg7M69VgLgkQnoMN39+7dZcGCBbJ27dpoP2HYc7PV3r17TfjWqSgRq5LYFUh0n/0zYlUSPa8BOE2aNJIiRQqz+WvjfRs6PUXniXuPfnu3iUgrq+gWkd4v4RsAACDpimmKcGigzqnR4D179mxZtWqVFClSJMbraLUSpSPgqnr16rJjxw6fqiRaOUXDbalSpTxtVq5c6XM72kYvVzqdpFKlSj5tdBqMnrfb6P5UqVL5tNHpL1rm0G4DAACA5CFloE410eohc+fONUP79tzpTJkymRFpnVqi+x966CFzkKLO+dZyf1oJ5e677zZttTShhuwnn3zSlCDU23j99dfNbdujzloXXKuY9O3bVzp27GiC/owZM0wFFJtOD2nfvr1UrlxZqlataqqraMnDDh06ePrUqVMn004PCNVwr5VQNHhT6QQAACCZsQKQdtvfNmHCBLP/0KFDVq1ataysWbNa4eHhVtGiRa0+ffpYZ8+e9bmdgwcPWo0aNbLSpEljZc+e3XrppZes69ev+7RZvXq1Vb58eSssLMy64447PPfhbcyYMVbBggVNm6pVq1obN2702X/58mXr+eeft7JkyWKlTZvWat68uXX06NFYP17ttz6+iP0HAABA0hDbvBYUdb6TwwR+HUHXAy+Z8w0AQODQmKWrZ2t1NAQ2Pc4vZcqUUc7pjm1eC8hpJwAAAEmdFlzQFbYvXbrkdleQQHS9GD1+UI/7iy/CNwAAQALTAgwHDhwwo6W65oiGNRbKC1z6DYZ+mNJV0PV1veuuu6JdSCc6hG8AAIAEpkFNA7jWfbZX10Zg06IeWsHur7/+Mq9v6tSp43U7AVlqEAAAIBDEd3QUwft68o4AAAAAHEL4BgAAABxC+AYAAECyEBISInPmzHG1D4RvAAAAeDz99NPSrFkzt7sRtAjfAAAAgEMI3wAAAA7Uib548aIr2+0sZv7AAw/ICy+8IH379pWsWbNK7ty5ZfDgwdFeR8vwde/e3SxGo+X4ChUqJEOHDvXs/+CDD6Rs2bKSLl06U4rx+eeflwsXLnj2T5w4UTJnziwLFiyQ4sWLm1KNrVq1MosVTZo0SQoXLixZsmQx/fJeOVQvHzJkiLRt29bcdr58+WTcuHHR9vXw4cPSunVrc3/6+B555BE5ePCgJCbqfAMAACQyDY7p06d35b412GoYjS8NvL1795affvpJNmzYYKal1KhRQ+rVq+e3/ejRo2XevHkyY8YMKViwoAm4unmX6xs9erQUKVJE9u/fb8K3hvuPPvrI5/nSNtOmTZPz589LixYtpHnz5iYkL1q0yFyvZcuWph+PPfaY53rDhw+XV199Vd544w1ZunSpvPjii1KsWDG/fb1+/bo0aNBAqlevLj/88INZOv6tt96Shg0byvbt229rFcvoEL4BAAAQpbvvvlsGDRpkTuvKjmPHjpWVK1dGGb4PHTpk2tWsWdMc4Kgj39569uzpM1qtgbdr164+4VuD8ccffyx33nmnOa8j319//bUcP37cfIgpVaqU1K5dW1avXu0TvjWMv/LKK+a0hu4ff/xRRo4c6bev06dPNwshff75557VRydMmGAC/po1a6R+/fqSGAjfAAAAiUynTnhPrXD6vm83fHvT6SQnTpwwpzU0T5482bNPH6OOjGvY1SkjOorcpEkTnyC7YsUKMw1l9+7dcu7cOblx44ZcuXLFjHbbfdWfdvBWuXLlMkHd+9sDvczuh01HsSOeHzVqlN/HtW3bNtm7d69kyJDB53Lty759+ySxEL4BAAASmY6s3s7UDzfpkuoRH4uOGKs333xTXn75ZZ/9FStWlAMHDsjixYtN0NY51XXr1pVZs2aZ+dQaxp977jl5++23zTzrdevWSadOncxccTt8+7vP6PoRH/pBoVKlSvLNN99E2pcjRw5JLIRvAAAAxEvOnDnNFlHGjBnNdBDddMqIjoCfOnVKNm/ebALziBEjPEu169zwhLJx48ZI50uWLOm3rX5I0Kkn2n/tr1OodgIAAIAEo9VMpk6daqaV/PHHHzJz5kxTJUXnUhctWtTM5x4zZow5aFLncY8fPz7B7lvneA8bNszcr1Y60fvWgy79efzxxyV79uymwokecKmj9TrXW6uo/P3335JYCN8AAABIMDqHWgNw5cqVpUqVKmaqiVYo0ZHucuXKmXD+3nvvSZkyZcyUD+8yhLfrpZdekl9++UUqVKhgDuTU+9KKJv7oFJe1a9eaiixaTUVHyHX6i875TsyR8BDrdoo/whF6MEKmTJnk7Nmzjn4tAgAA4kcDnI6kajk9rXWNxFe4cGFTScW7moqTr2ts8xoj3wAAAIBDCN8AAACAQ6h2AgAAgIB3MJGXhU8ojHwDAAAADiF8AwAAJBLqWgQXKwFeT8I3AABAArNXY9Ql0xE8Lv3/1zPiaptxwZxvAACABJYiRQqzqMyJEyc8NaV1OXQE7oi3Bm99PfV11dc3vgjfAAAAiUBXdVR2AEfg0+Btv67xRfgGAABIBDrSnSdPHsmZM6dZUh2BTaea3M6It43wDQAAkIg0sCVEaENw4IBLAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhhG8AAADAIYRvAAAAwCGEbwAAAMAhARm+hw4dKlWqVJEMGTJIzpw5pVmzZrJnzx7P/lOnTkmPHj2kePHikiZNGilYsKC88MILcvbsWZ/bCQkJibRNmzbNp82aNWukYsWKEh4eLkWLFpWJEydG6s+4ceOkcOHCkjp1aqlWrZps2rTJZ/+VK1ekW7duki1bNkmfPr20bNlSjh8/nuDPCwAAAJK2gAzf33//vQmzGzdulOXLl8v169elfv36cvHiRbP/yJEjZnv//fdl586dJjAvWbJEOnXqFOm2JkyYIEePHvVsGuRtBw4ckMaNG0vt2rVl69at0rNnT3nmmWdk6dKlnjbTp0+X3r17y6BBg2TLli1Srlw5adCggZw4ccLTplevXjJ//nyZOXOm6bv2rUWLFon+PAEAACBpCbEsy5IAd/LkSTMCrsG2Vq1aftto8H3iiSdMQE+ZMqW5TEe6Z8+e7RO4vfXr108WLlxoArytTZs2cubMGRPmlY506yj82LFjzflbt25JgQIFzMj7K6+8Ykbbc+TIIVOmTJFWrVqZNrt375aSJUvKhg0b5J577onx8Z07d04yZcpkbitjxozxeIYAAACQmGKb1wJy5DsiezpJ1qxZo22jT4QdvG06gp49e3apWrWqfPnll+L9WUTDcd26dX3a66i2Xq6uXbsmmzdv9mkTGhpqztttdL+OzHu3KVGihJkKY7eJ6OrVq+YF9N4AAAAQ+HyTaADSkWadDlKjRg0pU6aM3zb//vuvDBkyRJ599lmfy99880158MEHJW3atLJs2TJ5/vnn5cKFC2Z+uDp27JjkypXL5zp6XsPw5cuX5fTp03Lz5k2/bXR0276NsLAwyZw5c6Q2ui+qOe1vvPFGPJ4NAAAAJGUBH7515Fqnhaxbt87vfg3KOm+7VKlSMnjwYJ99AwYM8JyuUKGCmZIyfPhwT/h2S//+/c08cu/HoFNZAAAAENgCetpJ9+7dZcGCBbJ69WrJnz9/pP3nz5+Xhg0bmqooOrc7VapU0d6ezt/++++/zbQPlTt37khVSfS8Tl/RKio6XSVFihR+2+h17dvQ6Sk6TzyqNhFpZRW9D+8NAAAAgS8gw7fOy9bgrYF61apVUqRIkUhtdLRYK6DolI958+aZMoAx0YomWbJkMeFXVa9eXVauXOnTRqur6OVKb7tSpUo+bXQajJ632+h+Df3ebbQs4qFDhzxtAAAAkDykDNSpJlo9ZO7cuWZU2547rUeY6oi0HbwvXbokkydP9jloUSuP6Gi1lv7T0WetNqLBXEP1O++8Iy+//LLnfrp27WqqmPTt21c6duxogv6MGTNMBRSbTg9p3769VK5c2Ry0OWrUKDN9pUOHDp4+aYlDbacHhOootlZC0eAdm0onAAAACCJWANJu+9smTJhg9q9evTrKNgcOHDBtFi9ebJUvX95Knz69lS5dOqtcuXLW+PHjrZs3b/rcl96WtgsLC7PuuOMOz314GzNmjFWwYEHTpmrVqtbGjRt99l++fNl6/vnnrSxZslhp06a1mjdvbh09ejTWj/fs2bOm7/oTAAAASU9s81pQ1PkOdtT5BgAASNqSVZ1vAAAAIBAQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4RiWVZcuXKFbe7AQAAEHQI3/Bx69Yt6d69uzRp0oQADgAAkMAI3/Cxb98++eqrr2TlypXStm1buXHjhttdAgAACBqEb/i46667ZN68eRIeHi5z5syRTp06mdFwAAAA3D7CNyKpXbu2zJgxQ1KkSGFGwXv27GnmgQMAAOD2EL7h18MPPywTJ040p8eMGSODBw92u0sAAAABj/CNKD3xxBMyduxYc/rNN9+UkSNHut0lAACAgBaQ4Xvo0KFSpUoVyZAhg+TMmVOaNWsme/bs8WmjlTq6desm2bJlk/Tp00vLli3l+PHjPm0OHTokjRs3lrRp05rb6dOnT6QDDNesWSMVK1Y0c6CLFi3qGQ32Nm7cOClcuLCkTp1aqlWrJps2bYpzX5Iq7fdbb71lTvfu3Vu+/PJLt7sEAAAQsAIyfH///fcmFG7cuFGWL18u169fl/r168vFixc9bXr16iXz58+XmTNnmvZHjhyRFi1aePbfvHnTBO9r167J+vXrZdKkSSZYDxw40NPmwIEDpo3Ogd66dauZ+/zMM8/I0qVLPW2mT59uQumgQYNky5YtUq5cOWnQoIGcOHEi1n1J6l599VV5+eWXzenOnTvLrFmz3O4SAABAYLKCwIkTJ/RoQOv7778358+cOWOlSpXKmjlzpqfN77//btps2LDBnF+0aJEVGhpqHTt2zNPm448/tjJmzGhdvXrVnO/bt69VunRpn/t67LHHrAYNGnjOV61a1erWrZvn/M2bN628efNaQ4cOjXVfYnL27FnTXn+65datW9Yzzzxj+qGPZ8mSJa71BQAAIKmJbV4LyJHviM6ePWt+Zs2a1fzcvHmzGQ2vW7eup02JEiWkYMGCsmHDBnNef5YtW1Zy5crlaaMj1ufOnZNdu3Z52njfht3Gvg0dNdf78m4TGhpqztttYtOXiK5evWr64b25LSQkRMaPHy+tW7c2j6d58+by448/ut0tAACAgBLw4VtrUOt0kBo1akiZMmXMZceOHZOwsDDJnDmzT1sN2rrPbuMdvO399r7o2mgYvnz5svz7779m+oq/Nt63EVNf/M1pz5Qpk2crUKCAJAVaevDrr7+Whg0bmsevU3J0Og4AAACSSfjWud87d+6UadOmSbDo37+/Gc23t8OHD0tSoR8kvv32W6lZs6bpm861/+OPP9zuFgAAQEAI6PDdvXt3WbBggaxevVry58/vuTx37txmSsiZM2d82muFEd1nt4lYccQ+H1ObjBkzSpo0aSR79uxmNNhfG+/biKkvEWllFb0P7y0p0eow+rxXqFBBTp48aabUaOUYAAAABGH41tUWNXjPnj1bVq1aJUWKFPHZX6lSJUmVKpWsXLnSc5mWItSAWL16dXNef+7YscOnKolWTtGgW6pUKU8b79uw29i3oaPAel/ebXQajJ6328SmL4FIp8MsWbJEihcvbkbm69Wr5/NcAgAAwA8rAD333HNWpkyZrDVr1lhHjx71bJcuXfK06dq1q1WwYEFr1apV1i+//GJVr17dbLYbN25YZcqUserXr29t3brVVO/IkSOH1b9/f0+b/fv3W2nTprX69OljKpSMGzfOSpEihU+lj2nTplnh4eHWxIkTrd9++8169tlnrcyZM/tUUYmpL4FQ7SQqhw4dMo9N+1e+fHnr9OnTbncJAADAcbHNawEZvvWB+dsmTJjgaXP58mXr+eeft7JkyWICdPPmzU1A93bw4EGrUaNGVpo0aazs2bNbL730knX9+nWfNqtXrzahMiwszLrjjjt87sM2ZswYE0C1jZYe3Lhxo8/+2PQlUMO32rNnj5UzZ07Txxo1algXL150u0sAAACOim1eC9F//I2II+nQ6io6zUMPcExq879t27Ztk/vvv9/0UauhzJ0710zLAQAASA7OxTKvBeScbyQ9urLnokWLzMGYOhf8iSeeMGUYAQAA8D+EbySYe++91xwEqweYzpw5U7p06WIOjgUAAMD/IXwjQWnd76lTp5qVPr/44gvp06cPARwAAOD/I3wjwbVs2VI+++wzc3rEiBHyzjvvuN0lAACAJIHwjUTRsWNHGTlypDn9+uuvy9ixY93uEgAAgOsI30g0PXv2lIEDB5rTPXr0kMmTJ7vdJQAAAFcRvpGoBg8eLC+88II5/fTTT5sShAAAAMkV4RuJKiQkxEw/ad++vSk92Lp1a1m1apXb3QIAAHAF4RuJTiuffP7559K8eXO5du2aPPzww/LTTz+53S0AAADHEb7hiJQpU5oShHXr1pWLFy9Ko0aNZOfOnW53CwAAwFGEbzgmPDzcLMJzzz33yOnTp01N8H379rndLQAAAMcQvuGo9OnTy8KFC6Vs2bJy9OhRqVevnvzzzz9udwsAAMARhG84LmvWrLJs2TK588475cCBA2YE/L///nO7WwAAAImO8A1X5M6dW1asWCH58uWT3377TRo2bCjnzp1zu1sAAACJivAN1xQuXFiWL18u2bJlk19++cVUQbl8+bLb3QIAAEg0hG+4qmTJkrJ06VLJkCGDfP/996YO+PXr193uFgAAQKIgfMN1lSpVkgULFkjq1KnNT10J89atW253CwAAIMERvpEk1KpVS2bNmmXqgU+ZMkW6d+8ulmW53S0AAIAERfhGktG4cWP5+uuvzZL0H3/8sbz++utudwkAACBBEb6RpLRp08YEb/XOO+/IsGHD3O4SAABAgiF8I8np0qWLvPfee+Z0v3795NNPP3W7SwAAAAmC8I0kqW/fvvLKK6+Y0127dpXp06e73SUAAIDbRvhGkqXTTjR464GXTzzxhCxatMjtLgEAANwWwjeSLD3wcty4cdKuXTu5ceOGtGzZUtauXet2twAAAOKN8I0kLTQ0VCZOnChNmjSRK1eumJ+bN292u1sAAADxQvhGkpcqVSqZMWOG3H///XL+/Hlp2LCh7N692+1uAQAAxBnhGwEhTZo0Mm/ePKlcubL8+++/UrduXTl48KDb3QIAAIgTwjcCRsaMGWXx4sVSsmRJ+eeff6RevXpy7Ngxt7sFAAAQa4RvBJTs2bPL8uXLpXDhwrJ3716pX7++nD592u1uAQAAxArhGwEnX758smLFCsmdO7fs2LHDLEt/4cIFt7sFAAAQI8I3AtKdd94py5YtkyxZssiGDRukRYsWcvXqVbe7BQAAEC3CNwJW2bJlzRzwdOnSmakodj1wAACApIrwjYBWrVo1mTt3roSFhcl3330nnTt3llu3brndLQAAAL8I3wh4derUkenTp0uKFCnMgjy9e/c2S9IDAAAkNYRvBIVmzZrJl19+aU5/+OGH8uabb7rdJQAAgEgI3wgaTz31lIwePdqcHjx4sIwaNcrtLgEAAPggfCOo9OjRQ4YMGWJO9+rVSyZMmOB2lwAAADwI3wg6r732mpn3rZ555hlzICYAAEBSQPhG0AkJCZH3339fOnXqZCqftG3b1pQiBAAAcBvhG0EbwD/55BNp1aqVXLt2zRyQqYvxAAAAuInwjaClpQcnT54sDRo0kEuXLslDDz0k27Ztc7tbAAAgGSN8I6iFh4fLt99+KzVq1JAzZ85I/fr15c8//3S7WwAAIJkifCPo6fLzCxYskPLly8uJEyekbt26cvjwYbe7BQAAkiHCN5KFzJkzy9KlS6VYsWJy6NAhqVevnpw8edLtbgEAgGSG8I1kI2fOnKbqSYECBWTPnj1mLvjZs2fd7hYAAEhGCN9IVgoWLCgrVqyQHDlyyK+//ipNmzY1B2MCAAA4gfCNZEennugUlEyZMskPP/zgKUcIAACQ2AjfSJYqVKggCxculDRp0sjixYvlqaeekps3b7rdLQAAEOQI30i2tPygLj2fKlUqmT59ujz33HNiWZbb3QIAAEGM8I1krWHDhvLNN99IaGiofPbZZ9KvXz8COAAASDSEbyR7jz76qHz66afm9PDhw+Xdd991u0sAACBIEb4BEenUqZOMGDHCnH711Vflo48+crtLAAAgCBG+gf+vd+/eMmDAAHO6W7duZjoKAABAQiJ8A17eeOMN6dGjhzndvn17mT9/vttdAgAAQYTwDXgJCQmRUaNGyZNPPmlKD+p88NWrV7vdLQAAECQI30AEWvnkyy+/lEceeUSuXr0qDz/8sPz8889udwsAAAQBwjfgR8qUKWXatGny4IMPyoULF0xJwl27drndLQAAEOAI30AUUqdOLXPmzJFq1arJqVOnpF69erJ//363uwUAAAIY4RuIRoYMGWTRokVSpkwZOXr0qAngR44ccbtbAAAgQBG+gRhkzZpVli1bJnfccYcZ+a5fv778999/bncLAAAEIMI3EAt58uSRFStWSN68ec3c74ceekjOnz/vdrcAAECAIXwDsVSkSBFZvny5ZMuWTTZt2mSqoVy5csXtbgEAgABC+AbioFSpUrJkyRIzF1zrfz/22GNy/fp1t7sFAAACBOEbiKPKlSvLvHnzJDw83Pzs2LGj3Lp1y+1uAQCAAED4BuLhgQcekFmzZpl64JMnT5YXXnhBLMtyu1sAACCJI3wD8dSkSRP56quvzJL048aNkwEDBrjdJQAAkMQFZPheu3atNG3a1FSe0OCjC6F408v8bcOHD/e0KVy4cKT97777rs/tbN++Xe677z6z2EqBAgVk2LBhkfoyc+ZMKVGihGlTtmxZUxPam46GDhw40FTLSJMmjdStW1f+/PPPBH9O4I62bdvKRx99ZE6//fbb8v7777vdJQAAkIQFZPi+ePGilCtXzow2+qOLoXhvX375pQnXLVu29Gn35ptv+rTr0aOHZ9+5c+dMPedChQrJ5s2bTXAfPHiwfPrpp54269evN+GrU6dO8uuvv0qzZs3MtnPnTk8bDeyjR4+W8ePHy08//STp0qWTBg0aUCUjiHTt2lWGDh1qTvfp00c+//xzt7sEAACSKivA6UOYPXt2tG0eeeQR68EHH/S5rFChQtbIkSOjvM5HH31kZcmSxbp69arnsn79+lnFixf3nG/durXVuHFjn+tVq1bN6tKlizl969YtK3fu3Nbw4cM9+8+cOWOFh4dbU6dOjfVjPHv2rHmc+hNJV9++fc3rFBISYk2fPt3t7gAAAAfFNq8F5Mh3XBw/flwWLlxoRqcj0mkmWrO5QoUKZmT7xo0bnn0bNmyQWrVqSVhYmOcyHbHes2ePnD592tNGp5F40zZ6uTpw4IAcO3bMp02mTJmkWrVqnjb+XL161Yy8e29I+vT99Oyzz5qpRk888YQsXrzY7S4BAIAkJujD96RJk0xN5hYtWvhcrtUppk2bZmo1d+nSRd555x3p27evZ7+G5ly5cvlcxz6v+6Jr473f+3r+2vijUxg0pNubzjdH0qdTm3T+d5s2bUztb53m9MMPP7jdLQAAkISklCCn870ff/xxc0Ckt969e3tO33333WaEW0O4Bl+t3+ym/v37+/RPR74J4IEhRYoUpgKKvmZ68K1WRNEPeBUrVnS7awAAIAkI6pFvHXXUaSLPPPNMjG11KohOOzl48KA5nzt3bjNlxZt9XvdF18Z7v/f1/LXxR8N/xowZfTYEjlSpUpkqODptSUO4TkXavXu3290CAABJQFCH7y+++EIqVapkKqPEZOvWrRIaGio5c+Y056tXr25KGnovHb58+XIpXry4ZMmSxdNm5cqVPrejbfRyVaRIEROyvdtoGNOqJ3YbBKe0adPK/Pnzzfvv33//lXr16slff/3ldrcAAIDLAjJ8X7hwwYRl3ewDG/X0oUOHfEKujj76G/XWgx1HjRol27Ztk/3798s333wjvXr1MgfJ2cG6Xbt2ZiqKHqi5a9cumT59unz44Yc+00FefPFFWbJkiYwYMcKMbGopwl9++UW6d+/umQPcs2dPeeutt8wy5Dt27JCnnnrK1CfXkoQIbvqNhb4/tA7833//bQJ4xG9BAABAMmMFoNWrV5tSLhG39u3be9p88sknVpo0aUxpv4g2b95sSgJmypTJSp06tVWyZEnrnXfesa5cueLTbtu2bVbNmjVNacB8+fJZ7777bqTbmjFjhlWsWDErLCzMKl26tLVw4UKf/VpucMCAAVauXLnM7dSpU8fas2dPnB4vpQYD2+HDh01pS30Ny5UrZ50+fdrtLgEAgAQW27wWov+4/QEA0dNRfK16cvbsWeZ/B6i9e/dKzZo1zcj3vffeK8uWLTMLLgEAgOSV1wJy2gkQaIoWLWoCd+bMmc3KqFr6Uuu5AwCA5IXwDThES1rqwjs64q1BXEtgei/sBAAAgh/hG3DQPffcI3PmzDEH83777bdmRcxbt2653S0AAOAQwjfgsLp165rVVbW05YQJE+Sll14yS9IDAIDgR/gGXNC8eXOz+qrSspdDhgxxu0sAAMABhG/AJe3btze149WgQYNk9OjRbncJAAAkMsI34KIXXnhB3njjDc+iTZMmTXK7SwAAIBERvgGXDRgwwKyEqjp27CizZ892u0sAACCREL4Bl4WEhMiIESOkQ4cOpvJJmzZtZMWKFW53CwAAJALCN5AEaOWTTz/9VFq2bCnXrl2TZs2aycaNG93uFgAASGCEbyCJSJkypXzzzTdSv359uXjxojRq1Ei2b9/udrcAAEACInwDSUh4eLh89913cu+998qZM2dMEN+7d6/b3QIAAAmE8A0kMbr8/MKFC6VcuXJy/PhxsyjP33//7Xa3AABAAiB8A0lQ5syZZenSpXLXXXfJX3/9JfXq1ZOTJ0+63S0AAHCbCN9AEpUrVy5Zvny55M+fX3bv3m3mgJ87d87tbgEAgNtA+AaSsEKFCpkAnj17dtm8ebM0bdpULl++7Ha3AABAPBG+gSSuRIkSZgpKxowZZe3atdKqVStTjhAAAAQewjcQACpWrCgLFiyQNGnSyKJFi6R9+/Zy8+ZNt7sFAADiiPANBIj77rtPvv32W1MPfNq0adKtWzexLMvtbgEAgDggfAMBRA+61IV4dEn6Tz75RPr37+92lwAAQBwQvoEA07p1axO81XvvvSfvvvuu210CAACxRPgGAlDnzp1l+PDh5rSOfo8fP97tLgEAgFggfAMB6uWXX5bXXnvNnH7++edl6tSpbncJAADEgPANBLAhQ4Z4Drx86qmnTEUUAACQdBG+gQCmB16OHj1annjiCblx44Y8+uijsmbNGre7BQAAokD4BgJcaGiofPnll/Lwww/LlStXzCqYv/zyi9vdAgAAfhC+gSCQKlUqmT59utSuXVsuXLggDRs2lN9++83tbgEAgAgI30CQSJ06tcydO1eqVKki//33n9SrV08OHDjgdrcAAIAXwjcQRDJkyCCLFy+W0qVLy5EjR0wAP3r0qNvdAgAA/x/hGwgy2bJlk2XLlkmRIkVk3759Ur9+fTl16pTb3QIAAIRvIDjlzZtXVqxYIXny5JGdO3fKQw89ZOaCAwAAdxG+gSB1xx13yPLlyyVr1qzy008/SbNmzUw1FAAA4B7CNxDEdO63zgFPnz69rFy5Utq0aWPqgQMAAHcQvoEgV7VqVZk3b56Eh4ebaigdO3aUW7duud0tAACSJcI3kAxo/e+ZM2dKihQp5Ouvv5aePXuaJekBAICzCN9AMqErX06aNMksST9mzBgZNGiQ210CACDZIXwDycjjjz8uY8eONaeHDBkiH3zwgdtdAgAgWSF8A8nM888/L2+//bY5/dJLL8kXX3zhdpcAAEg2CN9AMtS/f3/p06ePOf3ss8/KrFmz3O4SAADJAuEbSIZ03vd7770nnTt3NpVP2rVrJ0uXLnW7WwAABD3CN5CMA/jHH38srVu3luvXr0vz5s1l3bp1bncLAICgRvgGkjG79GCjRo3k8uXL0qRJE9m6davb3QIAIGgRvoFkLiwszMz5vu++++Ts2bNSv359+eOPP9zuFgAAQYnwDUDSpk0r8+fPlwoVKsjJkyelbt26cujQIbe7BQBA0CF8AzAyZcpkDrosXry4HD58WOrVqycnTpxwu1sAAAQVwjcAjxw5csjy5culYMGCZupJgwYN5MyZM253CwCA5B2+t2/fbrZr167d1p2fOnVKRo8ebTYASUOBAgVkxYoVkitXLnPwpR6EeenSJbe7BQBAUAixLMuK65VCQ0PNpgG8VKlSkfYfPHhQOnbsaEqZrVy5Msrb2bVrl5QtW9bc1o0bN+Le+2Ti3LlzZkqAHgyXMWNGt7uDZGLbtm3ywAMPmJFvHQGfN2+eOTgTAADEP6/Fe9pJdJn94sWLsmbNGrPd7m0BcEe5cuVk4cKF5mBMnQv+xBNPyM2bN93uFgAAAY053wCidO+998qcOXMkVapUMnPmTOnSpQsflgEAuA2EbwDR0qonU6dONdPDvvjiC3n55ZcJ4AAAxBPhG0CMWrZsKZ9//rk5/cEHH8jbb7/tdpcAAAhIhG8AsdKhQwcZOXKkOT1gwAAZO3as210CACDgEL4BxFrPnj1l0KBB5nSPHj3kq6++crtLAAAEFMI3gDjR8P3iiy+a01pSdO7cuW53CQCAgEH4BhAnWr9f530//fTTpvRg69ato63nDwAA/iel3IajR49K+vTpI11+5MgRz+nDhw9HWRnBux2AwKGVTz777DOzkMDs2bPlkUceMQG8WrVqbncNAIDgXOFSR78Sgt693haLd0SNFS6RVF29etUsP6/L0WfJkkXWrl0rZcqUcbtbAAAE5wqXCbEBCFzh4eFm5Puee+6R06dPm5rg+/btc7tbAAAE17ST9u3bJ3xPAAQknXq2aNEiuf/++2XHjh1St25dWbduneTLl8/trgEAEBzTTuAspp0gEBw7dkzuu+8+2bt3r5QqVUq+//57yZ49u9vdAgAgOKadAIC33Llzy/Lly82I92+//SaNGjUyf4gAAMD/EL4BJJjChQubAK4j3r/88os8/PDDcvnyZbe7BQBA8gzf//33n5w6dcrJuwTgsJIlS8qSJUskQ4YMZuqJ1gG/fv26290CACB5hO/jx4/Ls88+a0bCcubMKTly5DAlyXSBjkOHDiX23QNwQaVKlWTBggWSOnVq81N/32/duuV2twAACMzw/ffff0vevHnN9vHHH0fZbv/+/eY/4S+++MKMeNvlBXUi+tdffy0VKlSQrVu33k7/ASRRtWrVkm+//VZSpkwpU6ZMke7du1NeFACQ7MUrfOtXylrZQAO1fqUclTZt2phVLO3/cAsUKGBWwNOvo/UyrQvctm1buXHjRpzuXxfyaNq0qQn/ukDPnDlzfPbrKJte7r01bNjQp432/fHHHzdHo2bOnFk6deokFy5c8Gmzfft2U71BR++078OGDYvUl5kzZ0qJEiVMm7Jly5qSa970cQ4cOFDy5MkjadKkMWXY/vzzzzg9XiBQPfTQQ+aDtv4O6gf11157ze0uAQAQeOF7w4YN5mft2rUlW7ZsftvoV816wJX+p5s1a1YT2P/66y9zXQ3uHTp0MO3++OMPMzoWFxcvXpRy5crJuHHjomyjYfvo0aOeberUqT77NXjv2rXLHBymfdVAr9NjbFqloX79+lKoUCHZvHmzDB8+XAYPHiyffvqpp8369evNhwcN7r/++qs0a9bMbDt37vS00cA+evRoGT9+vPz000+SLl06adCggVy5ciVOjxkIVPohXN//aujQoX4/xAIAkGxY8VClShUrNDTUGjFiRJRt2rRpY4WEhJh2EydOjLT/1q1b1t133232t23b1oovfQizZ8/2uax9+/bWI488EuV1fvvtN3O9n3/+2XPZ4sWLTX//+ecfc/6jjz6ysmTJYl29etXTpl+/flbx4sU951u3bm01btzY57arVatmdenSxfMYc+fObQ0fPtyz/8yZM1Z4eLg1derUWD/Gs2fPmv7qTyBQvffee+Z9rNsnn3zidncAAEhQsc1r8Rr5PnjwoPmpo89RWbNmjfmpxcbbtWsXab+OiHfs2NFMy9i2bZskNL1/PcCzePHi8txzz5lKKzYdfdepJpUrV/ZcptNBQkNDzei03UbnrIaFhXna6Ij1nj17zHQZu41ez5u2sb8ZOHDggBnl926jz4dOvbHb+HP16lUz8u69AYGub9++0r9/f3O6a9euMm3aNLe7BACA4+IVvu0wGNXqdRrOtcqJBmwNsKlSpfLbTg+4VDovPCHplJOvvvpKVq5cKe+9954pd6YLfty8edPs10CswdybHhSm02N0n90mV65cPm3s8zG18d7vfT1/bfzRr+Y1pNubzjcHgsHbb79tPgzrh+4nn3xSFi5c6HaXAABI+uFbQ7W6du2a3/2bNm3ynPYeXY5IR5/tOdwJPcdUF/fQAyB1DrbO6f755589o/FJnY4OakUYezt8+LDbXQIShP7tGDt2rPk2TA+0btWqlTneAgCA5CJe4ds+yFIPlvRHD0S0ValSJcrbOX/+vPmplUIS0x133GFG6ffu3etZBvvEiRM+bTQIaAUU3We30dF7b/b5mNp47/e+nr82/oSHh5sqLN4bECx0etfEiROlSZMm5sBj/akHNQMAkBzEK3zbc739VSnRr5PnzZvnmcpRo0aNKG9Hq5/4m5aR0LQuuc751nJ/qnr16nLmzBmf//BXrVplFgHR+dh2Gx2R816ZTyuj6BxyXSTIbqNTW7xpG71cFSlSxIRs7zY6ZUfnldttgORIp6LNmDFD7r//fvMhXKeK/f777253CwCApBm+dUqHhuy5c+eaGr7e3n//fTPnW79e1gMN06dPH+Xt2AcdaqCNC63HrYvz2Av06IGNelpXzNR9ffr0kY0bN5p+aPB95JFHpGjRouZgSHv5a/3PvnPnzmaKzI8//mgWANHpKlo7XOnX4nqwpZYR1JKE06dPlw8//FB69+7t6ceLL75oSiiOGDFCdu/ebUoRanlFvS2lz0HPnj3lrbfeMh9IduzYIU899ZS5D50OAyRnWvdefy90atq///4r9erV8xzMDQBA0IpPKZWLFy9aBQsWNGUCdatatarVrl07q0KFCua8XWJwxYoVUd6GluHLnz+/aTdkyJA43f/q1as9Jcu8Ny0xeOnSJat+/fpWjhw5rFSpUlmFChWyOnfubB07dsznNv777z9T4jB9+vRWxowZrQ4dOljnz5/3abNt2zarZs2apjRgvnz5rHfffTdSX2bMmGEVK1bMCgsLs0qXLm0tXLgw0uMcMGCAlStXLnM7derUsfbs2ROnx0upQQSzkydPWqVKlTLv8TvvvNM6evSo210CACDOYpvXQvSf+IR2HbXW0WP9ytg+APP/h3nzU0eMP/vssyivr1UOdJVKva6OPN9zzz3x6UayoFNVtOqJHnzJ/G8Eo3/++Udq1qxpRr71QGmtUGRP7wIAIJjyWrymnSids6xTLFq2bGkOmNTQrZuuCKlTT7xXgvRnyJAh5qfOiSZ4A8lbvnz5ZMWKFebvgU7P0mXpdQoZAADBJt4j3970QMWTJ0+aOdKxHa2yywvqQZla3QNRY+QbycXOnTvN2gC6kJUeM6JlQvn7AAAIBIk+8u1zI6GhpmJJXL4mTpcundn4jxWArUyZMrJ48WLzt0FHwtu2bWvKgAIAECwSJHwDQELRcp9aBUU/mM+ePVueeeYZ8+0aAADBIGV8rpQYK9LpV80AoB588EFT3lOPKZk0aZL5Gm/UqFE+B3cDAJBs5nzrNJOE/E9Qb4uvlqPGnG8kV7qOgNbGV4MGDTK19AEASLZzvu0KJwmxAUBETz75pIwZM8acfuONN8zoNwAAyW7aifcKdbp6pK5Mp6PhAJDQdMXYM2fOyIABA6RXr15mVKFDhw5udwsAAOemneh/frq4jrmBkBBTm1eXY9dRqrvvvjt+PUGUmHaC5E7/TPXp00dGjBhhPujPmDHDzAcHACBZTDs5fvy4TJ061SyEkSJFCjl69Kh88MEHUqFCBSlfvrw5rZcBQELQD/nDhw83K+dq5RMtQbhs2TK3uwUAgPOL7OjiOlOmTDEHRm3ZsuX/bjQkxIxO1alTxxws1bx5czNFBfHDyDfwf27evGmC98yZMyVt2rSyfPlyuffee93uFgAAEtu8liArXNp+//13+eqrr0wYP3z48P/dQUiIWTCjRYsWZlqKBnLEDeEb+J9r166ZY02WLFlifi++//57KVeunNvdAgAkc+fcCN/e1qxZY4L4t99+6zM/PG/evGY0/O23306Muw1KhG/A16VLl6R+/fry448/Ss6cOWXdunVy1113ud0tAEAyds7t8G27cuWKzJkzx0xL0a+ItZ536tSpzX+eiB3CNxCZVkCpXbu2bN26VQoWLGgCeIECBdzuFgAgmTrnRJ3v2LDnf+tPVqcDkFAyZ84sS5culWLFismhQ4dMydMTJ0643S0AABKvznd0dB6mjnbrtBP9JKB0kD1Pnjxm7jcA3C6dcqLfqNWsWVP27NkjDRs2lNWrV5uRBwAAgj586wGXGri9D7jUwK1VCbTiic711gMuWZAHQELRKScrVqwwAfzXX3+VJk2amBFx/bsDAEDQhW/9mldrfmvo1v/47MCtAVvnY2rg1konWvEEABKDTj3Rut8PPPCAmfvdqlUrc6xJWFiY210DAOD2D7iMeBCl1t61b6Z06dImcD/++OOmsgluHwdcArGj1U907vfly5eldevW5ls4XQgMAICkktdSxnee5cWLF81pDd26vLwufKFzuXWFSwBwQ40aNWT27NnStGlTswS9/vH79NNPOdgbABDYI9929RItGfjwww+beru3O7qko+Xwj5FvIG5mzZoljz32mFmK/uWXX5Zhw4YRwAEAgVvn2w7fCUVvS+t/wz/CNxB3X375pXTq1Mmc1kW9Xn31Vbe7BAAIYole51sze0JuAJCQOnbsKB988IE5/dprr8m4cePc7hIAAPGb8611dAEgqevVq5ecPn1ahgwZIt27dzcjEk888YTb3QIAJGOJvrw8bh/TToD40z9xL774oowZM8Ycm/Ldd9+ZY1UAAAjK5eUBwE16TMmoUaPMQd1aFlVLEPLtHQDALYRvAEFPDxL/4osvpFmzZnL16lUz8r1p0ya3uwUASIYI3wCShZQpU5rVeOvUqSMXLlyQRo0ayc6dO93uFgAgmSF8A0g2dG0CXZ23WrVqcurUKbNGwf79+93uFgAgGSF8A0hW0qdPL4sWLZIyZcrI0aNHpW7dunLkyBG3uwUASCYI3wCSnaxZs8qyZcvkzjvvlAMHDkjFihXlpZdekp9//pl1BwAAiYpSgwGAUoNA4jh48KDUrl3b/LRpIG/Tpo3ZdHQcAADXl5eHswjfQOLR6idLly6VadOmydy5c+XSpUuefaVLl5a2bdvKY489JkWLFnW1nwCApI3wHUQI34AzLl68KAsWLDBBXOeFX7t2zbOvcuXKZjRcg3j+/Pld7ScAIOkhfAcRwjfgvDNnzpjKKBrEV6xYYRbosd13330miLdq1Upy5szpaj8BAEkD4TuIEL4Bd508eVJmzZplgvgPP/zgOShTl6vXuuEaxJs3by6ZM2d2u6sAAJcQvoMI4RtIOv7++2+ZMWOGCeJaHcUWFhZmFu7RIN60aVNJly6dq/0EADiL8B1ECN9A0rRv3z6ZPn26WTnTe7XMtGnTmiXsNYg3bNhQwsPDXe0nACDxEb6DCOEbSPo0fNtBXEO5TX93dUqKVk158MEHzTL3AIDgQ/gOIoRvIHDon9TNmzebaSm6/fPPP559OXLkMAdpahCvUaOGhIayzhkABAvCdxAhfAOB6datW/Ljjz+aED5z5kxz4KYtX758pmyhBvFKlSpJSEiIq30FANwewncQIXwDge/GjRuyatUqE8S/++478/tsY1VNAAh8hO8gQvgGgm9VzSVLlpggPm/ePJ9VNTV824v5sKomAAQOwncQIXwDwb2q5vz5800QX7x4sc+qmlWqVDFBvHXr1qyqCQBJHOE7iBC+geS1qqZWTFm5cmWkVTV1frgesKkHbgIAkhbCdxAhfAPJz4kTJ+Tbb781QVxX1bTZq2pqEG/WrBmragJAEkH4DiKEbyB5s1fV1CD+yy+/eC5nVU0ASDoI30GE8A3AtnfvXs9iPrt27fJczqqaAOAuwncQIXwDiGpVTT1QU4P4/v37PZfr34sWLVqYIM6qmgDgDMJ3ECF8A4iO/hnX6SgaxHVUPOKqmo8++qgJ4qyqCQCJh/AdRAjfAOK6qqaOhuuqmv/++69nn5Yr1PrhGsRZVRMAEhbhO4gQvgHczqqaGsR1VU39W2LTBXzsVTVLly7taj8BIBgQvoMI4RvA7bpy5YosXbrUBHFdVfPy5cs+q2pq6UIdFdel7gEAcUf4DiKEbwAJ6cKFC7JgwYJoV9XUIJ4vXz5X+wkAgYTwHUQI3wASc1XN2bNnmyDuvaqmzgfXVTU1iLOqJgDEjPAdRAjfAJxaVXPWrFkmiEdcVbNu3bomiLOqJgD4R/gOIoRvAE47fPiwWVVTg3jEVTUfeughE8SbNGnCqpoA8P8RvoMI4RuA26tq2ov5/Pbbb57LNXjbq2o2aNCAVTUBJGvnCN/Bg/ANIFBW1dSqKbVr12ZVTQDJzjnCd/AgfAMIxFU1NYjfe++9rKoJIFk4R/gOHoRvAEl9Vc1169aZIM6qmgCSq3OE7+BB+AYQKK5fv25W1dQgzqqaAJKTc4Tv4EH4BhCoq2ouWbLEBPGIq2qWLVvWs5gPq2oCCAaE7yBC+AYQDKtqzp8/37Oqpo6Q26pWrWqCeOvWrVlVE0DAInwHEcI3gGBy+vRpn1U1dc6496qaeqBmy5YtWVUTQEAhfAcRwjeAYHX8+HHPqpp60Ka/VTWbN29u/gYCQDDktYCs/7R27Vpp2rSp5M2b14yUzJkzx7NPv8rs16+fmU+oC0Bom6eeekqOHDnicxuFCxc21/Xe3n33XZ8227dvN6MwqVOnlgIFCsiwYcMi9UWP7C9RooRpo/e5aNEin/362WbgwIGSJ08eSZMmjfnP5M8//0zw5wQAAlGuXLmkW7duZjn7Q4cOyfvvv2+qoty8eVOWLl0qHTp0kJw5c5oAriUNL1265HaXAeC2BGT4vnjxopQrV07GjRsXaZ/+Yd6yZYsMGDDA/NSj7ffs2WNWYYvozTfflKNHj3q2Hj16+Hx6qV+/vhQqVEg2b94sw4cPl8GDB8unn37qabN+/Xrz9WinTp3k119/lWbNmplNF6GwaWAfPXq0jB8/Xn766SfzgUBXgtMDkQAA/6ODHC+99JKpH/7HH3/IkCFDpFSpUnLt2jUzyKKj4BrE27VrZw7gvHr1qttdBoC4swKcPoTZs2dH22bTpk2m3V9//eW5rFChQtbIkSOjvM5HH31kZcmSxbp69arnsn79+lnFixf3nG/durXVuHFjn+tVq1bN6tKlizl969YtK3fu3Nbw4cM9+8+cOWOFh4dbU6dOjfVjPHv2rOm//gSA5ET/jm7fvt169dVXrTvuuMP8LbS3zJkzWx07drSWLVtmXb9+3e2uAkjmzsYyrwXkyHdc6dwbnVaSOXNmn8t1mkm2bNmkQoUKZmT7xo0bnn0bNmyQWrVqSVhYmOcyHbHWUXQ9WMhuo9NIvGkbvVwdOHBAjh075tNG5wJVq1bN08YfHc3RkXfvDQCSI/3brVP63n77bdm7d6/5BrFXr15mSuGZM2fkyy+/NN9SapWU7t27m3nj9gGcAJAUBX341ukdOgdcp4d4T35/4YUXzAE+q1evli5dusg777wjffv29ezX0KxzEb3Z53VfdG2893tfz18bf4YOHWpCur3pV7EAkNxpENeyhB988IEcPnxY1qxZI127djWDKCdOnDBTEfU4HT2mp0+fPmbKIDUFACQ1QR2+9eBLrRurf3w//vhjn329e/eWBx54QO6++27zx3vEiBEyZsyYJDGHsH///ma03t70PxkAwP+EhobK/fffb/626zE7uphP+/btzSCL/s3UAzcrV64sxYsXNwe9//bbb253GQCCO3zbwfuvv/6S5cuXx1iiT6eC6LSTgwcPmvO5c+c2JbC82ed1X3RtvPd7X89fG3/Cw8NNf703AIB/qVKlMlP+Jk6caP6+ag1x/fuvFaa0upQeuKnL2etgi37LuX//fre7DCAZCw3m4K1/dFesWGG+kozJ1q1bzUiKHkmvqlevbkoaeq/CpiFeR1GyZMniaaMLRHjTNnq5KlKkiAnZ3m10/rbOWbTbAAASjpZ91apTWpZQp6JMmTLFlKbVgL5jxw557bXXzHL2OuAycuRI+eeff9zuMoDkxgpA58+ft3799Vez6UP44IMPzGmtZnLt2jXr4YcftvLnz29t3brVOnr0qGezK5esX7/eVDrR/fv27bMmT55s5ciRw3rqqad8qpLkypXLevLJJ62dO3da06ZNs9KmTWt98sknnjY//vijlTJlSuv999+3fv/9d2vQoEFWqlSprB07dnjavPvuu+aI/Llz55oj9h955BGrSJEi1uXLl2P9eKl2AgC359SpU9YXX3xh1a1b1woNDfVUTAkJCbHuv/9+6+OPP7ZOnjzpdjcBBLDY5rWADN+rV6/2KTdlb+3bt7cOHDjgd59uej21efNmUxIwU6ZMVurUqa2SJUta77zzjnXlyhWf+9m2bZtVs2ZNUxowX758JkhHNGPGDKtYsWJWWFiYVbp0aWvhwoWRymQNGDDABHm9nTp16lh79uyJ0+MlfANAwjl27Jg1duxY8/fd+/+IFClSWA0bNrQmTpxoBmAAIDHyGsvLBwCWlweAxKGras6YMcNUv9LqKN7H3jz00ENmYZ8mTZpI2rRpXe0ngODJa4TvAED4BoDEp6tq6lzxqVOnyu+//+65XFcm1lWStWSt1hTXYA4AERG+gwjhGwCco/8t6sGZOhqumy6YZtPF2lq0aGGCuJarTZkypat9BZB0EL6DCOEbANyh/0X+/PPPZjRcR8W1prhNq2M9+uijJohrBSutmAUg+TpH+A4ehG8AcN/NmzfN8vU6Gj5z5kz577//PPt0JeLHHnvMzBGvWLGiWY0TQPJyjvAdPAjfAJC06BoQuoaDBnFd1Ef/TtvuuusuE8J1K1WqlKv9BOAcwncQIXwDQNJ15coVWbx4sQni8+fPl8uXL3v26aqaGsJ1VPyOO+5wtZ8AEhfhO4gQvgEgMJw/f94EcA3iS5Ys8VklWVfV1CCuKzDnzZvX1X4CSHiE7yBC+AaAwHPq1CkzJUWD+KpVq+TWrVvmcp0Pfv/995sg3rJlS8mePbvbXQWQAAjfQYTwDQCB7fjx4+YgTQ3iP/74o+fyFClSSL169UwQb9asmflbDyAwEb6DCOEbAIJrVU0tW6hBfMuWLZ7LWVUTCGyE7yBC+AaA4F1VU0O41hHfvXu3z6qajzzyiAniDRo0kLCwMFf7CSBmhO8gQvgGgOS9qqbODdcgzqqaQNJF+A4ihG8ASD70v+VNmzaZEO5vVU2tlqJBnFU1gaSF8B1ECN8AkHxX1fzhhx9MEJ81a5bPqpoFCxb0rKpZoUIFVtUEXEb4DiKEbwCA1gxfsWKFZ1VNrSluK1asmGdVzZIlS7raTyC5Okf4Dh6EbwBAxFU1Fy1a5FlVU89HXFVTtyJFirjaTyA5OUf4Dh6EbwBATKtqasWUpUuXsqom4BLCdxAhfAMA4rKqpgbx1atX+11Vs0aNGpIrVy7JmjWrWeQHQMIgfAcRwjcAIK6OHTtmDtLUIL5+/fpI+7VSii5trxVUNIzrz4invc+z6A8QPcJ3ECF8AwBux19//SUzZswwYXz//v2makpc//vXhX9iE9J1y5YtG2UQkeycI3wHD8I3ACAh3bhxQ/799185ceKEHD9+3PyMeNo+r9vVq1fjdPsavHPkyOE3mPs7nSZNmkR7rEBSy2sskwUAQDKjq2Tmzp3bbDHRMboLFy7EGNLt0zqqrnPN7eAeG+nTp49VSNdN56ozqo5Axsh3AGDkGwAQKLTair9R9ahG2eM6qq4HiUY1qu7vPKPqcAoj3wAAwHGpUqWSPHnymC0mOv6npRJjE9J102ouuuqnHkyqW2xkyJAh1tNfsmTJwqg6Eh0j3wGAkW8AAESuXbvmGVWPLqTbp7V9fEbVYzP9RbfUqVMn2mNF4GHkGwAABJWwsDCzWFBsFgzSsUUNQ7EJ6bqdPn06zqPqGrBiM/1FT2fOnJlRdRiMfAcARr4BAEhcOkp+8uTJWI+qe68kGtuDXCOOqkc3sh4eHp5ojxWJg5FvAACAOIyq58uXz2wx0XFLDVixHVU/c+aMKe949OhRs8WGhrfYTn/Rueq6iikCAyPfAYCRbwAAApdWdIlqVN3f+fiMqscmpOt5HX1nVD1xsMhOECF8AwCQPGgs05Hy2JZq1GwQV5opYjv9ReeqM6oeO4TvIEL4BgAAUY2qRzeKHvG8Tn+Ja+nI2IR0e9PpO8nVOcJ38CB8AwCA26Urj8ZlVF3zR1zpSHlspr/kzJnTZJtgGlUnfAcRwjcAAHDalStXfAJ6dAeV6qalGuMiLCws0sh5VKFd56on9VF1wncQIXwDAICkPqqutdJjW6rx/Pnzcb4PreoS2wNLNS85PapO+A4ihG8AABBMLl++bCrAxKZUo7aL76h6jRo1ZNq0aeIE6nwDAAAgSUqTJo0ULFjQbLEZVT916lSspr7o+QsXLphFk/7++28T3JMawjcAAACSrNDQUMmePbvZSpUqFWP7S5cueUbVtQZ6UpP0egQAAADEU9q0aaVQoUJmS4pC3e4AAAAAkFwQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcQvgEAAACHEL4BAAAAhxC+AQAAAIcEZPheu3atNG3aVPLmzSshISEyZ84cn/2WZcnAgQMlT548kiZNGqlbt678+eefPm1OnToljz/+uGTMmFEyZ84snTp1kgsXLvi02b59u9x3332SOnVqKVCggAwbNixSX2bOnCklSpQwbcqWLSuLFi2Kc18AAACQPARk+L548aKUK1dOxo0b53e/huTRo0fL+PHj5aeffpJ06dJJgwYN5MqVK542Grx37doly5cvlwULFphA/+yzz3r2nzt3TurXry+FChWSzZs3y/Dhw2Xw4MHy6aefetqsX79e2rZta4L7r7/+Ks2aNTPbzp0749QXAAAAJBNWgNOHMHv2bM/5W7duWblz57aGDx/uuezMmTNWeHi4NXXqVHP+t99+M9f7+eefPW0WL15shYSEWP/88485/9FHH1lZsmSxrl696mnTr18/q3jx4p7zrVu3tho3buzTn2rVqlldunSJdV9i4+zZs6a/+hMAAABJT2zzWkCOfEfnwIEDcuzYMTO9w5YpUyapVq2abNiwwZzXnzrVpHLlyp422j40NNSMTtttatWqJWFhYZ42OmK9Z88eOX36tKeN9/3Ybez7iU1f/Ll69aoZeffeAAAAEPiCLnxr2FW5cuXyuVzP2/v0Z86cOX32p0yZUrJmzerTxt9teN9HVG2898fUF3+GDh1qQrq96XxzAAAABL6gC9/BoH///nL27FnPdvjwYbe7BAAAgAQQdOE7d+7c5ufx48d9Ltfz9j79eeLECZ/9N27cMBVQvNv4uw3v+4iqjff+mPriT3h4uKnC4r0BAAAg8AVd+C5SpIgJtitXrvRcpnOmdS539erVzXn9eebMGVPFxLZq1Sq5deuWmY9tt9EKKNevX/e00cooxYsXlyxZsnjaeN+P3ca+n9j0BQAAAMlHQIZvrce9detWs9kHNurpQ4cOmbrfPXv2lLfeekvmzZsnO3bskKeeesrUBNcygKpkyZLSsGFD6dy5s2zatEl+/PFH6d69u7Rp08a0U+3atTMHW2oZQS1JOH36dPnwww+ld+/enn68+OKLsmTJEhkxYoTs3r3blCL85ZdfzG2p2PQFAAAAyYgVgFavXm1KuUTc2rdv7ynxN2DAACtXrlymrF+dOnWsPXv2+NzGf//9Z7Vt29ZKnz69lTFjRqtDhw7W+fPnfdps27bNqlmzprmNfPnyWe+++26kvsyYMcMqVqyYFRYWZpUuXdpauHChz/7Y9CUmlBoEAABI2mKb10L0H7c/ACB6OlVFq57owZfM/wYAAAjcvBaQ004AAACAQET4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcErThu3DhwhISEhJp69atm9n/wAMPRNrXtWtXn9s4dOiQNG7cWNKmTSs5c+aUPn36yI0bN3zarFmzRipWrCjh4eFStGhRmThxYqS+jBs3zvQnderUUq1aNdm0aVMiP3oAAAAkRUEbvn/++Wc5evSoZ1u+fLm5/NFHH/W06dy5s0+bYcOGefbdvHnTBO9r167J+vXrZdKkSSZYDxw40NPmwIEDpk3t2rVl69at0rNnT3nmmWdk6dKlnjbTp0+X3r17y6BBg2TLli1Srlw5adCggZw4ccKx5wIAAABJQ4hlWZYkAxqMFyxYIH/++acZ5daR7/Lly8uoUaP8tl+8eLE0adJEjhw5Irly5TKXjR8/Xvr16ycnT56UsLAwc3rhwoWyc+dOz/XatGkjZ86ckSVLlpjzOtJdpUoVGTt2rDl/69YtKVCggPTo0UNeeeWVWPX93LlzkilTJjl79qxkzJgxAZ4NAAAAJKTY5rWgHfn2pqPXkydPlo4dO5rgbfvmm28ke/bsUqZMGenfv79cunTJs2/Dhg1StmxZT/BWOmKtT+yuXbs8berWretzX9pGL7fvd/PmzT5tQkNDzXm7jT9Xr1419+O9AQAAIPCllGRgzpw5ZjT66aef9lzWrl07KVSokOTNm1e2b99uRrH37Nkj3333ndl/7Ngxn+Ct7PO6L7o2GpYvX74sp0+fNtNX/LXZvXt3lP0dOnSovPHGGwnwyAEAAJCUJIvw/cUXX0ijRo1M0LY9++yzntM6wp0nTx6pU6eO7Nu3T+68805xk47C6zxxm4Z5naoCAACAwBb04fuvv/6SFStWeEa0o6Jzs9XevXtN+M6dO3ekqiTHjx83P3Wf/dO+zLuNzvNJkyaNpEiRwmz+2ti34Y9WTtENAAAAwSXo53xPmDDBlAnUqiTR0WolSkfAVfXq1WXHjh0+VUm0YooG61KlSnnarFy50ud2tI1ervSgzEqVKvm00QMu9bzdBgAAAMlHUIdvDboavtu3by8pU/5vkF+nlgwZMsQcDHnw4EGZN2+ePPXUU1KrVi25++67TZv69eubkP3kk0/Ktm3bTPnA119/3dQJt0eltS74/v37pW/fvmYO90cffSQzZsyQXr16ee5Lp4989tlnplTh77//Ls8995xcvHhROnTo4MIzAgAAADcF9bQTnW6iC+VolRNvOiKt+7TMoAZhnU/dsmVLE65tOl1ESxNqWNZR6nTp0pkQ/+abb3raFClSxJQa1LD94YcfSv78+eXzzz83FU9sjz32mClNqPXB9QBNLW+oZQgjHoQJAACA4Jds6nwHMup8AwAAJG3U+QYAAACSGMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOCQoAzfgwcPlpCQEJ+tRIkSnv1XrlyRbt26SbZs2SR9+vTSsmVLOX78uM9tHDp0SBo3bixp06aVnDlzSp8+feTGjRs+bdasWSMVK1aU8PBwKVq0qEycODFSX8aNGyeFCxeW1KlTS7Vq1WTTpk2J+MgBAACQlAVl+FalS5eWo0ePerZ169Z59vXq1Uvmz58vM2fOlO+//16OHDkiLVq08Oy/efOmCd7Xrl2T9evXy6RJk0ywHjhwoKfNgQMHTJvatWvL1q1bpWfPnvLMM8/I0qVLPW2mT58uvXv3lkGDBsmWLVukXLly0qBBAzlx4oSDzwQAAACSihDLsiwJwpHvOXPmmFAc0dmzZyVHjhwyZcoUadWqlbls9+7dUrJkSdmwYYPcc889snjxYmnSpIkJ5bly5TJtxo8fL/369ZOTJ09KWFiYOb1w4ULZuXOn57bbtGkjZ86ckSVLlpjzOtJdpUoVGTt2rDl/69YtKVCggPTo0UNeeeWVWD+ec+fOSaZMmUzfM2bMeNvPDwAAABJWbPNaSglSf/75p+TNm9dM96hevboMHTpUChYsKJs3b5br169L3bp1PW11Sorus8O3/ixbtqwneCsdsX7uuedk165dUqFCBdPG+zbsNjoCrnTUXO+rf//+nv2hoaHmOnrd6Fy9etVsNn0R7RcVAAAASY+d02Ia1w7K8K0jzjpNpHjx4mbKyRtvvCH33XefGaU+duyYGbnOnDmzz3U0aOs+pT+9g7e9394XXRt94i9fviynT58201f8tdGR9ujoBwXtc0Q6ag4AAICk6/z582YEPFmF70aNGnlO33333SaMFypUSGbMmCFp0qSRpE5Hy3WuuE2nq5w6dcocIKoHjyY2/QChQf/w4cNMcwGAIMLfdyDx6Ii3Bm+deRGdoAzfEekod7FixWTv3r1Sr149MyVE52Z7j35rtZPcuXOb0/ozYlUSuxqKd5uIFVL0vP4x04CfIkUKs/lrY99GVLR6im4RH4PT9LHwxxkAgg9/34HEEd2Id9BXO/F24cIF2bdvn+TJk0cqVaokqVKlkpUrV3r279mzx5QW1LnhSn/u2LHDpyrJ8uXLzR+qUqVKedp434bdxr4Nndqi9+XdRkew9bzdBgAAAMlLUIbvl19+2ZQQPHjwoCkV2Lx5czMK3bZtW/OJpFOnTmZax+rVq81BkR06dDCBWA+2VPXr1zch+8knn5Rt27aZ8oGvv/66qQ1uj0h37dpV9u/fL3379jVzuD/66CMzrUXLGNr0Pj777DNTqvD33383B2xevHjR3B8AAACSn6CcdvL333+boP3ff/+ZsoI1a9aUjRs3mtNq5MiRpvKILq6jVUW0SomGZ5sG9QULFpiwrKE8Xbp00r59e3nzzTc9bYoUKWJKDWrY/vDDDyV//vzy+eefm9uyPfbYY6Y0odYH1wM0y5cvb8oQRjwIM6nRDxhamzzi1BcAQGDj7zvgvqCs8w0AAAAkRUE57QQAAABIigjfAAAAgEMI3wAAAIBDCN8AAACAQwjfiGTcuHFSuHBhSZ06tVkdNOKCQwCAwDF06FCpUqWKZMiQQXLmzCnNmjUz61sAcAfhGz6mT59u6pNrKaotW7ZIuXLlTPlE7wWHAACBQ9e90HUqtOSuLgZ3/fp1s56FrjsBwHmUGoQPHenWEZKxY8d6VuUsUKCA9OjRQ1555RW3uwcAuE26/oSOgGsor1WrltvdAZIdRr7hce3aNbPiZ926dT2X6WJEen7Dhg2u9g0AkDDOnj1rfmbNmtXtrgDJEuEbHv/++6/cvHkz0gqcel5X6AQABDb9NrNnz55So0YNKVOmjNvdAZKloFxeHgAARKZzv3fu3Cnr1q1zuytAskX4hkf27NklRYoUcvz4cZ/L9Xzu3Lld6xcA4PZ1795dFixYIGvXrpX8+fO73R0g2WLaCTzCwsKkUqVKsnLlSp+vKPV89erVXe0bACB+tK6CBu/Zs2fLqlWrpEiRIm53CUjWGPmGDy0z2L59e6lcubJUrVpVRo0aZcpRdejQwe2uAQDiOdVkypQpMnfuXFPr2z6GJ1OmTJImTRq3uwckO5QaRCRaZnD48OHmD3T58uVl9OjRpgQhACDwhISE+L18woQJ8vTTTzveHyC5I3wDAAAADmHONwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3AAAA4BDCNwAAAOAQwjcAAADgEMI3ACQxN2/elA8//FCqVq0qGTNmNCsU6tasWbM439ahQ4ekS5cucuedd0rq1Kk9tzVnzpxE6TsiGzx4sOd5h7vWrFnjeS30NOCGlK7cK4AYbdiwQe69915JmzatnD17VlKm/L9f1zNnzki2bNnk1q1b8tdff0nBggXd7ioSWNu2bWXmzJm3fTsavCtVqiT//vtvgvQLAHD7GPkGkqgff/zR/KxWrZoneNuXa/AuUKCAq8H7gQceMKNH+hMJZ/369Z7g3bhxY1m+fLls375dduzYIaNHj47Tbb311lsmeOv757333jMf6PR2dKtTp04iPQIkJYy6A0kPI99AEg/fNWvW9Ln8hx9+8Hs5gsOKFSvMzxQpUsiUKVPMtJPbvS2drtK3b98E6yMQqHSwwLIst7uBZI6RbyAJj4D6C9nr1q3zezmCwz///GN+5sqV67aCt/dtFStWLEH6BgC4fYRvIAnau3evnDhxwox+Vq9e3XP5lStX5OeffzanCd/B6erVq+ZnqlSpbvu2rl27lmC3BQBIGIRvIAlPObn77rslQ4YMnss3bdpkAlXmzJmlTJkyCXJfegDn22+/bUJ+lixZTFDLkSOHlCpVSpo3by4ff/yxHD9+3NP+6aefNvNHv//+e3Nef9pzSu2tcOHCfu9LDxwdOnSo1KhRw9xHWFiY5MmTR5o2bSqzZs2K9utg+7Z1Dqs9peLhhx8219cqHnfccYd0797dM9qbUI83PnRO9bPPPit33XWXOWBWX8PSpUtLr1695ODBg9E+vkmTJpnzejBtxOc1NiZOnBip/RtvvOFzO/oaRnTy5El5/fXXpUKFCub9pc+pvo5PPvmk59uWqGg779vdvHmzOV2kSBEJDw/39EVfHz2tr5k/+tzYfQwNDZVTp05FanPjxg3zfGqbV155JdL+jRs3mseh0wty585t3mP6DYK+vs8995z89ttv0T4W+/1tv4ePHj0q/fr1M6+ffb8Rq2T8/fff0q1bN/Me1Octb9685r1pT/tJqAo4+to2aNDA87gyZcpk3mM6f/+dd97xeWz2+0Bfe1vE95Nu/t6Pel/6PmzSpIl5LPoa6kHe+oH/gw8+kMuXL8f6WJA9e/aY3wV9L+hzo69969atzevkj/4dsPu2e/fuaN9v0VXtadiwodl/zz33xLnayR9//CE9evQwf2P1NdfnWp+H8uXLS8eOHWX69OmeD8n+HDt2TF577TWpXLmyZM2a1Tx/eoyOPu6EfE8ggFkAXDVhwgRNnLe9HThwIM73/dtvv1l58+aN8bbHjBnjuU779u1jbF+oUKFI97VixQorW7Zs0V7voYcess6fP++3r3abQYMGWYMHD47yNjJlymStXbs2wR5vXL3zzjtWaGholLcdHh5uTZo0KcrHF92WUO8nfQ29LV261MqYMWO01+nWrZt18+ZNv/epr7d9ux9//LGVMmVKv32fMWOG5/zvv/8e6XYmTpzoc53Zs2dHarNx40bP/sWLF8f5sadIkcIaN25clM+f/f7Wx7RhwwYre/bskW5j9erVnvb6XovuudP3qr5n4/IaRqS/E/fdd1+Mj61ly5Zxei78/d3466+/rHLlykV7naJFi1p79uzx29f777/ftNGfixYtstKlS+f3NvR3ZOTIkZGuf+LECU8bfS9FdPDgQZ/befHFFyO1uX79upU+fXqzv1+/fj779LXz9zra9D0aFhYW4/O2Y8cOv49/8uTJUT5me+vUqZPpI5IvDrgEkjEd1Txy5IgZ/e3cubM0atTIjKppNRUdzdPRqdmzZ/tcR0eNX375ZenQoYP88ssvZnRnwoQJPm10pCjiSL7e9vXr181cZh1VKleunBlN0vvXkaTJkyfLokWLpH379vLtt99G2eeFCxea+y1evLg5iFC/HdARda0Q8tlnn5nTOmK3c+dOM9p0u483Lj766CN59dVXzWkdTdcRUx3l15FEHfEaPny4XLx40YyuZs+eXR566CGf0XKlo7Zz5841z83SpUvj3Ac9uFJfE1W2bFnzU0d8n3/+eU8bHfG3bd261XzzoN+o6POio9M6apsuXTr59ddf5d1335UDBw7IuHHjzGVaNSUqOiVKX0d93vU9ov3QkWr7IOH777/f01ZHHUuUKOFz/YgjkXo+Ym1zu41WcNHn1pvelz62Rx55RGrVqmVGhbXP+ppv2bLFVIvR6i/6GPW+H3zwwSgfy4ULF6Rly5ZmqpeOYtarV898i6Gvkz1yr6Uc9b127tw5M1KvI7ytWrUyI9JaoUafO/2mxn494ktvw34O9f4ef/xxU+lIR5J1epq+TgsWLPD5tsN+H+h7Ur/N8X6PecuXL5/n9H///WdGtw8fPmxGa/V3RF8zHWnW52PZsmWm/rxOi9PfHX1O9bH6o895u3btzOuko/L2SPjq1avNe0ifM/0mSG/b+zW2v4XSUXx9rbt27RrjeyQi/eZF+xvxPRcT/cZL/67p70LOnDnN+0RHzvV3VUf79XHrN31RjbbPmDHD/I3Rz9L2N3H6WPQx6TcMX3zxhfkbpz/12xj9FgHJlNvpH0juzpw5Y0YB7c17ZGbdunWey3ft2mWlTp3aXD5r1iyf6+h27dq1ON3vvn37YjXSe+vWLevUqVPRjnBFR/tVuHBh07Zhw4bWxYsX/bb79NNPPf1ZtmxZpP3eI0cVK1b0O0L+1Vdfedo8+uijCfp4Y6IjdmnTpjW3r6Prhw4ditRmy5YtnlGxfPny+X3NvEdeb5f9eHXkNSpVqlTxjAjrCHhE+lyUKlXKM1q5c+fOKEe+dStbtqx1+vTpKO+vZMmSpt1jjz0WaV+RIkXMvqZNm5qfOgIbUaNGjcy+qlWrRtr3999/R/n+sn/X7r77bnP9mjVr+m3j/c2Ojp5u3bo1yttr1aqVp+2UKVMi7T937lykUeT4KFCggLmu3l90/vvvv0iXxWXUvV27dp733v79+/228X4Pv/rqq1H+XbC/hdJvmyLS95D9bYG/34PnnnvO7MudO3ek63bo0MHnPRISEhLpcb/33nue97S+BrEd+f7iiy9iHNlWly5dMpu3kydPmser1+3YsWOUI9v6nNm/S7t3747yPhDcCN9AEmN/Na9BxJuGAL08TZo0cQ7a/vz444+e/2i2bdsW5+vHNnzbgVg/OGhAjY4GKm2rISAi7wDzyy+/RHkbdjjTqQ9Hjx5NsMcbE/s/fN2mTZsWZbu33nrL005fazfD908//eRp07Vr1yhvRz8E2u2ef/75aMN3VFN+YgpWOt3BDlP6+voLVjdu3LAyZMhg9vXp08eKjzlz5nj6+u+//0Ybvt98880ob0ffWxrutF2TJk2ibOf9HMc3fKdKlcpc98MPP4zzdWMbvnX6if145s+fH23bvn37ej5kRhe+33///Vj9vsycOdNn3/Tp06OcnmR/QNPr2KcjTk+y/wboB8uIogvfb7/9trk8S5YsVlzpe8X+MHHlypUo22ko1zZRfXhB8sABl0ASE1Udb/sgTP0qOSGqV3gf9KYHZyWWefPmeb7+1a9fo6NTBZQuBhMVnUqhqzZGRQ+IsqcgeH8lndiP1z6QSg9WbNGiRZTtnnnmmUjXcYv3/Xfq1CnKdjq9o2TJkpGuE5FON7nvvvuivU97GoAelOZ9QJ19AK9+Ta+vrx6gp58f1q5d62mj0xzOnz9vTsdmcSed4qNf9+/atctMQ9LN+3dn27Zt0V5fp3dERadP6HQipVMVolK1alVzsObtsN+7Oj3r0qVLkhh0Opc+Hp1ao1NKYvN7qlNLdOqNPzoFRqeQRUWfM3uaTMT3VMTpSTadDqNToPR62sZ+D3i30cdg/62M6wJg9vN8+vRpM/UrPn/ndFqQTtmJik7DsStYRfd3DsGN8A0kMVHV8bbrfkec5xpfGm7soDRy5EgTEAYOHCirVq1K0P/gdX620vnL/qoteG/vv/++J5hFpUqVKtHen4Ydm/cc18R+vBrsVMWKFaP9cKRz3u1KGvZ13GLfv87R10oO0dGVVtWff/7pKWEYkc6/j0lUwco+bQcmf8HKPq0lOKMqtalzunXevR4ToJUq9HXXqhX6oU03XTXUu21U0qdPb+btRsX7vRWX92R82CFW/wbo49G5xHpsglaoSejfU/1d0IAY3e+pBkxbVL+r2k+dKx0V/SBu/x5EnIuuvyP28QD+Xn97HrW/94h+QNP55HGd7630WAf98Ky08pEeE6B/K3QOuf1Byx/dp8dOqE8++STGv3Na0SWmv3MIboRvIAnRUT09UCu6ke977703we5v6tSpnlEYPcBpyJAhpmyZ/geko1vjx483B5zdDj0gLK6iK2WmB0JFR//jtkUsVZeYj9e+r5j6p/QgT3/9c5p9/1oOTQNXbPqso9E6MuiP94Gc0d2OBuOIocke+Y4ufNtttByivwWINCRpaNNyllouLqaVDKN7n9khLCrer11c3pPxMWDAAPONjgY3/X3Sg1/12xW9X/1gMWjQoNsujxmf31MV1QfX2Pwe2M+Lv98DOzjbr3l07xH9m2nfht1GP6DF9C1MRFpOUUew9SBUfe/otxu9e/f2lAzU51wPbI1I71u/aYurxPoWA0kf1U4AF+nIj9Zz9ieqr6p1dMab/sdr176OK/1PRkfTVq5cKd999535j0tDqVYl0ekvuulotB6hH99VEu0RI/0qe9iwYXK7Ylvv2q3Hezv9c0tC9VkDT2xoaNL6z3ZQ0trs+/bt80wnUPZPO1hpGLa/FfI3oqmj8VpHWSt26DcPWlFHq57o66gfCuypAPv375c777zTnI4unMf2sTjxmuvj0QoZL730kvkAqd/W6Ei1PmadUqObVs7QSjP6mG/n91RHqzV0xpaOcCfGc6LvER1Ftqcn6YeqiOFbK77o31CdWqTTk7Rqit1Gv8mJzwqxGti1qolWXNK/A3q7WglJR9P12wbdtNa6/v3QKTrKe1Rcp5W9+OKLsbqviFWhkHwQvgGY0V/dlIYXnYP56aefmv/kNRQ99thjppxZfOhoks4N1aCQEAsDxTTC571fR6ucerx6X7ogS2xGIO2vm6Pqn1Ps+9fnQEfuohv9tvusoSo2I9zR0fDsHax0xNp7OoEqVKiQT7DS+eRaRjKqubz62mmwVlpez3tuvbeE+rbB+znQ1zxiWUtvtzsqbdPnR7+t0U2/odEPI1OmTJGvvvrKlNZr27atef9GtYhRTL+n9rdvOr8/Lh8+4vuY7Tb+fg8iTk/SKUQair0/oNnvBT2GQ9vowIR9zExc53t70xKOOt/fnvOv88x1TvyYMWPMNyo6hU7LT+qUlIj91w90CbUAGoIX004AF2ndXJ3vaG/2gYT6h937cp1/qPQ/A+/LdfOu35wQ9D9hDZ86OmyPsut8Rp3rG5+RLZ0ioOyRutultaRjuz82/wnG9vHGxL4vnXMa3VfQ+vW+/W2H2/9J2/evr4s9ZzUqurqq0trZtzti5x2MNDRFHNGM2M67jdbT9jedQEd/bfp6xjS3+XbZNdTj+p5MKBoQ69atK19++aWpH29Po4k4LSKuv6e6cmNCPEcaWPVDXVR0vrq9uqa/3wP9AGF/++T9+nt/QIv4HtH3sP0BLa7zvaNjz7PX1zF//vyemt42/X2wv6m0pwcC0SF8Ay7S/1z0Px7ddB7s77//bi7XuYX25brpV/RKD3Tyvly32MytjC97dNjfwWn6n7+KbpllZQda/U8x4mI88aEfOKIbldYwonTkLq6jX9E93phoELKXr9evpKOi0wfs6Q72ddziff/28+aPVmWwly5PiD5rsNIQb4emiAdb+gtWdhudTuBvYRfvDzxa5cQfXUxJF2JKCLVr1/aMDutS7FHRwJbYB9bG5vc0pt9VXWjJDuqjRo267T7pe1xH5KOio9Ux/R54z/uO6T2i05Ps37uoPqDdLp3GYh9cG/F5tv/O6Tc58VkcC8mM27UOAfwfXcpafyW1jrHWM7ZpLWKtd6z7/vnnnwS7v19//dVs0S02472QxZEjR/wudpEzZ07TNipa89ZeJEQXLfn++++j7dcPP/xgrVmzJtLl3rWSK1eubF24cCFSm2+++cbvUtsJ8XjjsshO/vz5zYIvEWmtdnvZ66SyyI4+l3Zd9BUrVvhdmEYXzrEXBvG3+Ij38vKx1blzZ3Mde7EVfc4j1oHX2tP2Pru+d69evfze3rfffut5vEOHDo22PrW96RLst/P8t2jRwnNbWps6Il0IqkKFCrdV51vrnM+bNy/a37Hhw4d7bn/q1Kk++yZNmuTZpwt1Rad169aetiNGjIi2rS7C429hIe8631ov299CMrrwjr0gTZ48eayrV6/6vQ/v32e7fcSa4N7vP7uNPudRia7O95IlS6L9vdffBbtGd/HixX32HTt2zPO7rY/J32JU3hYsWJAo6w0gMBC+gSTCXnSiQYMGfhcFKVq0aILenwYPeyEKXSBC/zPQxU30Q4D+p1qvXj3Pf1KPPPJIpOt/9tlnnv09e/Y01/3zzz/NdvDgQZ+2epvh4eGeVecef/xx85+oXmfTpk3W3LlzrYEDB3pCnr8VKL2Dt/4sUaKEeQx6GytXrjSLt2g4tD/AaHBLyMcbG+PGjfPcRq5cuayRI0eaRVZ0gZ833njD85+zhsmFCxf6vQ2nw7d+IAkLCzPt9OdLL71kPvz8/PPPZtXRO+64w3M7Gl79iU/4njx5sk8oLV26dLS3bW/6XvFHP4zpB0H7PdalSxcTpvQ11kWP6tSpY/bVqFEjwcK3vsfsDwV6n7oA0apVq8x9fvnll1axYsV83rPxCd/2BxBdJbZ3794m5G/cuNHchy6G8+yzz3re9xoMI678qr+P9n3Xr1/ffPj9448/PL+r3isxatD3fr1r1aplff755+Z3RFe2XL58uVk4p27duuY+I37A9Q7f+vdKw3DmzJnNhyG9Dd30tB2S7dV6o6IfYL1fe38f0CIujBTdB7SYwrfeji5o9NBDD1mjRo0yH0b1cetzpr/b9uqsuunvtr8PgPZAiS4qpgtX6ft18+bN5jXTx6q/Q/ZzHNNiRghehG8giWjcuLH5g6wrIHrTMGQvWZyQ7DAa03bvvff6XQlQ/5P3/o/ae/MXXPQ/XnsEPKZNR+uiC5Leq/ZF3HQk1d/I+e0+3tjSVfLsMORv0w8h/h6fW+Fb6bLy9gh0VFu3bt2smzdvJlj4jhis9Pb98Q5W+rzqcvdR0bCtoSeqx/DAAw+YEcmECt9KA5wdwP1t+qEyLku8RxW+Y9p0tDWqlV+9R7QjbhE/pOrKnffdd1+s7lO//Ypu5Vv9gGt/GxRx09cyuhUwbRriY/qAFvF3Wwcs4hu+Y/O4NVRH9bug31JkzZo1xtvQx68f1JA8Eb6BJED/kOsIkf5Rjjgtw15yfeLEiQl6nzodZNGiRWaUqGbNmmapZv2PUkc/ddrEww8/bL72jeo/Gfur1hdffNGMCHn/JxtVcNH7HD9+vPmgoUtT631pWNJQrqNyGlz9fU3tL0hq0NLb0RFmvR0dGdSRx8OHDyfa440t/TpZp1XceeedVpo0aax06dKZ50ifq4hhJymEb6Ujirrcdfny5U0Q1w8JBQsWNN9S6FSg6MQnfCt9fuw++ptOEDFYad9iouH6iSeeMO8vHcXMkSOHCYI6iq+vrXeYTYjwrQ4dOmS+edHr6PtJ35P63tT3qLqd8K3TTfTbocGDB5vfEZ3uoH8rdJpQ9uzZzei0Tjs5e/ZslLeh05uGDRtm/pboqLP3h8Oo3o8anPW11w/Y+ntiP5f64VQHBKKaPuYdvu0pJhrS7edGv53QEfP169fH6vF36tQpxg9o3q9pTB/Qogvfej39RkYHOvTbCv0mQfusv8P6LYa+N2L6XVD6WugHiwcffNC8F/S509vQvzlNmjSxPvjgA/OeQfIVov+4Pe8cAGJiHwx2O3XNASQuPQBSD5DUgyW9F0gC8D9UOwEAAAAcQvgGAAAAHEL4BgAAABxC+AYAAAAcQvgGAAAAHEK1EwAAAMAhjHwDAAAADiF8AwAAAA4hfAMAAAAOIXwDAAAADiF8AwAAAA4hfAMAAAAOIXwDAAAADiF8AwAAAOKM/wcYmQngDFaZGQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_fig, ax = subplots(figsize=(8,8))\n",
    "insample_mse = ((Yhat_in - Y[:,None])**2).mean(0)\n",
    "n_steps = insample_mse.shape[0]\n",
    "ax.plot(np.arange(n_steps),\n",
    "        insample_mse,\n",
    "        'k', # color black\n",
    "        label='In-sample')\n",
    "ax.set_ylabel('MSE',\n",
    "              fontsize=20)\n",
    "ax.set_xlabel('# steps of forward stepwise',\n",
    "              fontsize=20)\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.legend()\n",
    "ax.set_ylim([50000,250000]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7508e0",
   "metadata": {},
   "source": [
    "Notice the expression `None` in `Y[:,None]` above.\n",
    "This adds an axis (dimension) to the one-dimensional array `Y`,\n",
    "which allows it to be recycled when subtracted from the two-dimensional `Yhat_in`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9531a",
   "metadata": {},
   "source": [
    "We are now ready to use cross-validation to estimate test error along\n",
    "the model path. We must use *only the training observations* to perform all aspects of model-fitting --- including\n",
    "variable selection.  Therefore, the determination of which model of a\n",
    "given size is best must be made using \\emph{only the training\n",
    "  observations} in each training fold. This point is subtle but important.  If the full data\n",
    "set is used to select the best subset at each step, then the validation\n",
    "set errors and cross-validation errors that we obtain will not be\n",
    "accurate estimates of the test error.\n",
    "\n",
    "We now compute the cross-validated predicted values using 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1654ad8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a function that uses 5 fold cv to predict the response variable\n",
    "\n",
    "K = 5 \n",
    "kfold = skm.KFold(n_splits = K)\n",
    "Yhat_cv = skm.cross_val_predict(skl.LinearRegression(), X = X, y = Y[:, None], cv = kfold)\n",
    "Yhat_cv.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b49cb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 291.32035967,  735.98970301, 1241.95654469,  594.67771035,\n",
       "        484.71869592,  301.15457347,   14.70601665,   71.7978124 ,\n",
       "        635.25284346,  937.08565641,  217.39166594,  499.23847987,\n",
       "        338.8835088 ,  396.36630501, 1191.47274922,   36.64896814,\n",
       "        125.93985119,  520.59627948,  311.40641574,  556.52375027,\n",
       "       1560.53292206,  676.46770864,  258.63295406,  475.77532331,\n",
       "        619.9638559 ,  682.01700365,   92.43731943,  602.456638  ,\n",
       "        151.9387061 ,  766.95239809,  139.11670316,  366.44383053,\n",
       "        250.3373919 ,  296.84401863,  334.38612222,  259.90608821,\n",
       "        690.38067462,  689.60581758,  293.66378682,  735.60348026,\n",
       "        778.04249344,   59.57592817,  248.28841468,  267.38505922,\n",
       "       1166.67222421,  328.17457539,  302.23179703,   49.17368299,\n",
       "        108.19247588, 1165.68659629,  129.65148493,  379.09269133,\n",
       "        688.44639232,  663.28682558, 1184.11821251, 1138.55549329,\n",
       "        457.2859574 ,  434.92941844,  365.57786782,  281.85778592,\n",
       "        838.75808512, 1220.41562359, 1018.46854098,  561.94723146,\n",
       "       1105.38463327,  454.64463223,  551.91710485,  308.98486364,\n",
       "        263.59266409,  660.84226142,  199.7135084 ,  304.37215858,\n",
       "        501.55048768, 1295.43815103,  504.49619357,  375.14548415,\n",
       "       1453.77441524,  167.57866237,  848.46388698,  616.52014652,\n",
       "        141.67253529, 1282.32533632,  518.3277913 , 1041.82179456,\n",
       "        689.67000311,  553.54743167,  196.22870414,  823.8926897 ,\n",
       "        599.17555696,  287.32520248, 1113.16375864,  804.70611198,\n",
       "        382.71314681,  567.32312941,  679.70569182,  468.73520697,\n",
       "        556.64106584,  509.97106913,  655.27479341,  574.64622442,\n",
       "        325.05355795,  741.22304107,  173.06328988,  214.05380255,\n",
       "        236.58775739,  801.90461061,  738.93863161,  164.71475082,\n",
       "        351.3762571 ,  651.15514184,  866.36798313,  814.77731171,\n",
       "        569.3970942 ,  375.09031833,  751.53374496,  563.46914067,\n",
       "        560.69424764,  193.07336957,  437.59792104,  427.43391564,\n",
       "        690.32821479,  156.43877173,  691.15599342,  391.58413199,\n",
       "        981.30731419,   85.46051486, 1757.62905333,  484.10603749,\n",
       "        366.46365844,  609.56848566,  213.21438013,   68.53814123,\n",
       "        116.08629081,  342.96965697,  361.38450079,  636.76702395,\n",
       "        303.64892608,  824.3651024 , 1033.86024952, 1493.56721379,\n",
       "        883.78371237,  451.83227878,  675.71083302,  419.48508296,\n",
       "        601.22846481,  562.98202661,  523.13786503,  701.43672865,\n",
       "        166.36820569,  958.93761881,  600.31447337,  554.2422701 ,\n",
       "        716.9431972 ,  305.83751998,  690.03072595,  798.75900866,\n",
       "        841.70732845,  358.18126225,  888.33340726,  261.4430909 ,\n",
       "        677.99286981,  376.01008026,  281.85477926,   71.58066973,\n",
       "        845.35745725,  509.21351124,  352.28517344,   86.7161699 ,\n",
       "        383.98202213,  290.93525904,  341.38668088,  168.84699598,\n",
       "        131.262792  ,  459.36772653,  221.3312446 ,  296.40944972,\n",
       "        603.81596808,  562.4643069 ,  137.83183672,  479.10067348,\n",
       "        129.69757198,  429.34093665,  549.03901662,  468.50718618,\n",
       "        764.43086926,  322.39504759,  214.61153567,  738.68751016,\n",
       "       1350.26263623,  232.87881236,  764.58748358,  237.50454755,\n",
       "        433.72452144,  317.14268822,  279.48158335,  974.1306621 ,\n",
       "        416.98678909,  354.35161454,  644.30343953,  928.06227309,\n",
       "       1690.98740342,  288.97500342,  684.79757324,  259.78065228,\n",
       "        268.30738251,  427.14892981,  471.32019994,  126.04401478,\n",
       "        108.11904252,  109.13675323,  437.64884357, 1137.37476476,\n",
       "        339.71729715,  313.37123083,  120.11043053,  341.04529462,\n",
       "        528.78076598,  175.88936713, 1379.70490032,  594.46599749,\n",
       "        203.26199301, 1017.58587272,  169.2365779 ,  480.15310021,\n",
       "        557.97574252, 1504.70459915,  482.98862237,  372.04103771,\n",
       "        265.62353933, 1030.5583246 ,  942.07169842,  446.44352723,\n",
       "        368.26607888,  792.98867209,  502.81393874,  368.74588684,\n",
       "        812.91295764,  134.56759348,  906.22138195,  -30.79679222,\n",
       "        313.22563695,  243.87687101,  200.08725071,  378.64573693,\n",
       "        914.44631271,  379.038689  ,  488.85972048,  266.19024119,\n",
       "        867.81744077,  413.32637679,  480.63284527,  330.85794781,\n",
       "       1346.5496153 ,  475.19467254,  716.83351428, 1285.47328576,\n",
       "        646.78875413,  871.46832142,  629.78992459,  984.32115806,\n",
       "        194.20692307, 1173.92719816,  666.81188246])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yhat_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dfabdc",
   "metadata": {},
   "source": [
    "`skm.cross_val_predict()`\n",
    "The prediction matrix `Yhat_cv` is the same shape as `Yhat_in`; the difference is that the predictions in each row, corresponding to a particular sample index, were made from models fit on a training fold that did not include that row.\n",
    "\n",
    "At each model along the path, we compute the MSE in each of the cross-validation folds.\n",
    "These we will average to get the  mean MSE, and can also use the individual values to compute a crude estimate of the standard error of the mean. {The estimate is crude because the five error estimates  are based on overlapping training sets, and hence are not independent.}\n",
    "Hence we must know the test indices for each cross-validation\n",
    "split. This can be found by using the `split()` method of `kfold`. Because\n",
    "we  fixed the random state above, whenever we split any array with the same\n",
    "number of rows as $Y$ we recover the same training and test indices, though we simply\n",
    "ignore the training indices below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce919bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mse = []\n",
    "for train_idx, test_idx in kfold.split(Y):\n",
    "    errors = (Yhat_cv[test_idx] - Y[test_idx,None])**2\n",
    "    cv_mse.append(errors.mean(0)) # column means\n",
    "cv_mse = np.array(cv_mse).T\n",
    "cv_mse.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27004be",
   "metadata": {},
   "source": [
    "We now add the cross-validation error estimates to our MSE plot.\n",
    "We include the mean error across the five folds, and the estimate of the standard error of the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "687ee72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(121136.31031816857)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26520d22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'x' and 'y' must have the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43merrorbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m            \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcv_mse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcv_mse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCross-validated\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# color red\u001b[39;00m\n\u001b[32m      7\u001b[39m ax.set_ylim([\u001b[32m50000\u001b[39m,\u001b[32m250000\u001b[39m])\n\u001b[32m      8\u001b[39m ax.legend()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/MXN442-Codebase/mxn442_venv/lib/python3.12/site-packages/matplotlib/_api/deprecation.py:453\u001b[39m, in \u001b[36mmake_keyword_only.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > name_idx:\n\u001b[32m    448\u001b[39m     warn_deprecated(\n\u001b[32m    449\u001b[39m         since, message=\u001b[33m\"\u001b[39m\u001b[33mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[33m; the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparameter will become keyword-only in \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    452\u001b[39m         name=name, obj_type=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/MXN442-Codebase/mxn442_venv/lib/python3.12/site-packages/matplotlib/__init__.py:1524\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1521\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1530\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1531\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/MXN442-Codebase/mxn442_venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:3712\u001b[39m, in \u001b[36mAxes.errorbar\u001b[39m\u001b[34m(self, x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, **kwargs)\u001b[39m\n\u001b[32m   3710\u001b[39m x, y = np.atleast_1d(x, y)  \u001b[38;5;66;03m# Make sure all the args are iterable.\u001b[39;00m\n\u001b[32m   3711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) != \u001b[38;5;28mlen\u001b[39m(y):\n\u001b[32m-> \u001b[39m\u001b[32m3712\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must have the same size\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3714\u001b[39m everymask = \u001b[38;5;28mself\u001b[39m._errorevery_to_mask(x, errorevery)\n\u001b[32m   3716\u001b[39m label = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: 'x' and 'y' must have the same size"
     ]
    }
   ],
   "source": [
    "ax.errorbar(np.arange(5), \n",
    "            cv_mse.mean(1),\n",
    "            cv_mse.std(1) / np.sqrt(K),\n",
    "            label='Cross-validated',\n",
    "            c='r') # color red\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.legend()\n",
    "mse_fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9881566e",
   "metadata": {},
   "source": [
    "To repeat the above using the validation set approach, we simply change our\n",
    "`cv` argument to a validation set: one random split of the data into a test and training. We choose a test size\n",
    "of 20%, similar to the size of each test set in 5-fold cross-validation.`skm.ShuffleSplit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c9091",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "validation = skm.ShuffleSplit(n_splits=1, \n",
    "                              test_size=0.2,\n",
    "                              random_state=0)\n",
    "for train_idx, test_idx in validation.split(Y):\n",
    "    full_path.fit(Hitters.iloc[train_idx],\n",
    "                  Y[train_idx])\n",
    "    Yhat_val = full_path.predict(Hitters.iloc[test_idx])\n",
    "    errors = (Yhat_val - Y[test_idx,None])**2\n",
    "    validation_mse = errors.mean(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7421fc11",
   "metadata": {},
   "source": [
    " As for the in-sample MSE case, the validation set approach does not provide standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca6b08",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ax.plot(np.arange(n_steps), \n",
    "        validation_mse,\n",
    "        'b--', # color blue, broken line\n",
    "        label='Validation')\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.legend()\n",
    "mse_fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9dd7d4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "D = design.fit_transform(Hitters)\n",
    "D = D.drop('intercept', axis=1)\n",
    "X = np.asarray(D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87bd74",
   "metadata": {},
   "source": [
    "Here we excluded the first column corresponding to the intercept, as\n",
    "`l0bnb` will fit the intercept separately. We can find a path using the `fit_path()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed84ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5. Number of non-zeros:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6. Number of non-zeros:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7. Number of non-zeros:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8. Number of non-zeros:  9\n",
      "Iteration: 9. Number of non-zeros:  9\n",
      "Iteration: 10. Number of non-zeros:  9\n",
      "Iteration: 11. Number of non-zeros:  9\n",
      "Iteration: 12. Number of non-zeros:  9\n",
      "Iteration: 13. Number of non-zeros:  9\n",
      "Iteration: 14. Number of non-zeros:  9\n",
      "Iteration: 15. Number of non-zeros:  9\n",
      "Iteration: 16. Number of non-zeros:  9\n",
      "Iteration: 17. Number of non-zeros:  9\n",
      "Iteration: 18. Number of non-zeros:  17\n",
      "Iteration: 19. Number of non-zeros:  19\n"
     ]
    }
   ],
   "source": [
    "path = fit_path(X, \n",
    "                Y,\n",
    "                max_nonzeros=X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9ca6a",
   "metadata": {},
   "source": [
    "The function `fit_path()` returns a list whose values include the fitted coefficients as `B`, an intercept as `B0`, as well as a few other attributes related to the particular path algorithm used. Such details are beyond the scope of this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc2ef8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "path[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a96126",
   "metadata": {},
   "source": [
    "In the example above, we see that at the fourth step in the path, we have two nonzero coefficients in `'B'`, corresponding to the value $0.0114$ for the penalty parameter `lambda_0`.\n",
    "We could make predictions using this sequence of fits on a validation set as a function of `lambda_0`, or with more work using cross-validation.\n",
    "\n",
    "## Ridge Regression and the Lasso\n",
    "We will use the `sklearn.linear_model` package (for which\n",
    "we use `skl` as shorthand below)\n",
    "to fit ridge and  lasso regularized linear models on the `Hitters` data.\n",
    "We start with the model matrix `X` (without an intercept) that we computed in the previous section on best subset regression.\n",
    "\n",
    "### Ridge Regression\n",
    "We will use the function `skl.ElasticNet()` to fit both  ridge and the lasso.\n",
    "To fit a *path* of ridge regressions models, we use\n",
    "`skl.ElasticNet.path()`, which can fit both ridge and lasso, as well as a hybrid mixture;  ridge regression\n",
    "corresponds to `l1_ratio=0`.\n",
    "It is good practice to standardize the columns of `X` in these applications, if the variables are measured in different units. Since `skl.ElasticNet()` does no normalization, we have to take care of that ourselves.\n",
    "Since we\n",
    "standardize first, in order to find coefficient\n",
    "estimates on the original scale, we must *unstandardize*\n",
    "the coefficient estimates. The parameter\n",
    "$\\lambda$ in (6.5) and (6.7) is called `alphas` in `sklearn`. In order to\n",
    "be consistent with the rest of this chapter, we use `lambdas`\n",
    "rather than `alphas` in what follows.  {At the time of publication, ridge fits like the one in code chunk [22] issue unwarranted convergence warning messages; we expect these to disappear as this package matures.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d6fc8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# fit a ridge regression model below as per the explanation provided\n",
    "\n",
    "# Xs = \n",
    "# X_scale =  \n",
    "# Xs = Xs / X_scale[None,:]\n",
    "#lambdas = 10**np.linspace(8, -2, 100) / Y.std()\n",
    "#soln_array = skl.ElasticNet.path(...)[1]\n",
    "soln_array.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7770f5",
   "metadata": {},
   "source": [
    "Here we extract the array of coefficients corresponding to the solutions along the regularization path.\n",
    "By default the `skl.ElasticNet.path` method fits a path along\n",
    "an automatically selected range of $\\lambda$ values, except for the case when\n",
    "`l1_ratio=0`, which results in ridge regression (as is the case here). {The reason is rather technical; for all models except ridge, we can find the smallest value of $\\lambda$ for which all coefficients are zero. For ridge this value is $\\infty$.}  So here\n",
    "we have chosen to implement the function over a grid of values ranging\n",
    "from $\\lambda=10^{8}$ to $\\lambda=10^{-2}$ scaled by the standard\n",
    "deviation of $y$, essentially covering the full range of scenarios\n",
    "from the null model containing only the intercept, to the least\n",
    "squares fit.\n",
    "\n",
    "Associated with each value of $\\lambda$ is a vector of ridge\n",
    "regression coefficients,   that can be accessed by\n",
    "a column of `soln_array`. In this case, `soln_array` is a $19 \\times 100$ matrix, with\n",
    "19 rows (one for each predictor) and 100\n",
    "columns (one for each value of $\\lambda$).\n",
    "\n",
    "We transpose this matrix and turn it into a data frame to facilitate viewing and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))\n",
    "soln_path.index.name = 'negative log(lambda)'\n",
    "soln_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246bb2b",
   "metadata": {},
   "source": [
    "We plot the paths to get a sense of how the coefficients vary with $\\lambda$.\n",
    "To control the location of the legend we first set `legend` to `False` in the\n",
    "plot method, adding it afterward with the `legend()` method of `ax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc997b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "path_fig, ax = subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficients', fontsize=20)\n",
    "ax.legend(loc='upper left');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73ca09",
   "metadata": {},
   "source": [
    "(We have used `latex` formatting in the horizontal label, in order to format the Greek $\\lambda$ appropriately.) \n",
    "We expect the coefficient estimates to be much smaller, in terms of\n",
    "$\\ell_2$ norm, when a large value of $\\lambda$ is used, as compared to\n",
    "when a small value of $\\lambda$ is used. (Recall that the  $\\ell_2$ norm is the square root of the sum of squared coefficient values.) We display  the coefficients at the $40$th step,\n",
    "where $\\lambda$ is 25.535."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7359c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hat = soln_path.loc[soln_path.index[39]]\n",
    "lambdas[39], beta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa8b00",
   "metadata": {},
   "source": [
    "Let’s compute the $\\ell_2$ norm of the standardized coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2984305",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(beta_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111fc6f",
   "metadata": {},
   "source": [
    "In contrast, here is the $\\ell_2$ norm when $\\lambda$ is 2.44e-01.\n",
    "Note the much larger $\\ell_2$ norm of the\n",
    "coefficients associated with this smaller value of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3424a4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "beta_hat = soln_path.loc[soln_path.index[59]]\n",
    "lambdas[59], np.linalg.norm(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50239927",
   "metadata": {},
   "source": [
    "Above we normalized `X` upfront, and fit the ridge model using `Xs`.\n",
    "The `Pipeline()`  object\n",
    "in `sklearn` provides a clear way to separate feature\n",
    "normalization from the fitting of the ridge model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = skl.ElasticNet(alpha=lambdas[59], l1_ratio=0)\n",
    "scaler = StandardScaler(with_mean=True,  with_std=True)\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('ridge', ridge)])\n",
    "pipe.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8c514",
   "metadata": {},
   "source": [
    "We show that it gives the same $\\ell_2$ norm as in our previous fit on the standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07da6e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(ridge.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20ea7e",
   "metadata": {},
   "source": [
    " Notice that the operation `pipe.fit(X, Y)` above has changed the `ridge` object, and in particular has added attributes such as `coef_` that were not there before. \n",
    "### Estimating Test Error of Ridge Regression (Home practice)\n",
    "Choosing an *a priori* value of $\\lambda$ for ridge regression is\n",
    "difficult if not impossible. We will want to use the validation method\n",
    "or cross-validation to select the tuning parameter. The reader may not\n",
    "be surprised that the  `Pipeline()` approach can be used in\n",
    "`skm.cross_validate()` with either a validation method\n",
    "(i.e. `validation`) or $k$-fold cross-validation.\n",
    "\n",
    "We fix the random state of the splitter\n",
    "so that the results obtained will be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = skm.ShuffleSplit(n_splits=1,\n",
    "                              test_size=0.5,\n",
    "                              random_state=0)\n",
    "ridge.alpha = 0.01\n",
    "results = skm.cross_validate(ridge,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=validation)\n",
    "-results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f962ee",
   "metadata": {},
   "source": [
    "The test MSE is 1.342e+05.  Note\n",
    "that if we had instead simply fit a model with just an intercept, we\n",
    "would have predicted each test observation using the mean of the\n",
    "training observations. We can get the same result by fitting a ridge regression model\n",
    "with a *very* large value of $\\lambda$. Note that `1e10`\n",
    "means $10^{10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2b24d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ridge.alpha = 1e10\n",
    "results = skm.cross_validate(ridge,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=validation)\n",
    "-results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78a776c",
   "metadata": {},
   "source": [
    "Obviously choosing $\\lambda=0.01$ is arbitrary,  so we will  use cross-validation or the validation-set\n",
    "approach to choose the tuning parameter $\\lambda$.\n",
    "The object `GridSearchCV()`  allows exhaustive\n",
    "grid search to choose such a parameter.\n",
    "\n",
    "We first use the validation set method\n",
    "to choose $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b76df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'ridge__alpha': lambdas}\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=validation,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befd23e",
   "metadata": {},
   "source": [
    "Alternatively, we can use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c1b53",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.713e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.627e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.727e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.454e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.286e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.402e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.969e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.314e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.966e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.145e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.865e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.249e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.843e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.824e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.223e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.047e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.743e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.700e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.000e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.169e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.971e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.717e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.156e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.630e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.956e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.701e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.966e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.138e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.575e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.933e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.554e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.668e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.933e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.535e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.661e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.122e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.911e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.655e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.915e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.496e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.487e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.899e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.644e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.480e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.897e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.640e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.110e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.469e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.465e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.462e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.891e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.460e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 5.332e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.01185247763144249, l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.01185247763144249, l1_ratio=0))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.01185247763144249, l1_ratio=0)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge', ElasticNet(alpha=0.01185247763144249, l1_ratio=0))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = skm.GridSearchCV(pipe, \n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae429da",
   "metadata": {},
   "source": [
    "Recall we set up the `kfold` object for 5-fold cross-validation on page 271. We now plot the cross-validated MSE as a function of $-\\log(\\lambda)$, which has shrinkage decreasing from left\n",
    "to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            yerr=grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854e0c21",
   "metadata": {},
   "source": [
    "One can cross-validate different metrics to choose a parameter. The default\n",
    "metric for `skl.ElasticNet()` is test $R^2$.\n",
    "Let’s compare $R^2$ to MSE for cross-validation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ab0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.713e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.627e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.727e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.454e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.286e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.402e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.969e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.314e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.966e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.145e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.865e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.249e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.843e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.824e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.223e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.047e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.743e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.700e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.000e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.169e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.971e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.717e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.156e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.630e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.956e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.701e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.966e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.138e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.575e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.933e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.554e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.668e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.933e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.535e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.661e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.122e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.911e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.655e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.915e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.496e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.487e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.899e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.644e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.480e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.897e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.640e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.110e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.469e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.465e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.462e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.891e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.460e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+06, tolerance: 4.201e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/jonathantaylor/anaconda3/envs/ISLP_test2025/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 5.332e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;ridge&#x27;,\n",
       "                                        ElasticNet(alpha=10000000000.0,\n",
       "                                                   l1_ratio=0))]),\n",
       "             param_grid={&#x27;ridge__alpha&#x27;: array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606...\n",
       "       4.67486141e-03, 3.70474772e-03, 2.93594921e-03, 2.32668954e-03,\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;ridge&#x27;,\n",
       "                                        ElasticNet(alpha=10000000000.0,\n",
       "                                                   l1_ratio=0))]),\n",
       "             param_grid={&#x27;ridge__alpha&#x27;: array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606...\n",
       "       4.67486141e-03, 3.70474772e-03, 2.93594921e-03, 2.32668954e-03,\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05])})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.01185247763144249, l1_ratio=0))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.01185247763144249, l1_ratio=0)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('ridge',\n",
       "                                        ElasticNet(alpha=10000000000.0,\n",
       "                                                   l1_ratio=0))]),\n",
       "             param_grid={'ridge__alpha': array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606...\n",
       "       4.67486141e-03, 3.70474772e-03, 2.93594921e-03, 2.32668954e-03,\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05])})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_r2 = skm.GridSearchCV(pipe, \n",
    "                           param_grid,\n",
    "                           cv=kfold)\n",
    "grid_r2.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3887a9c",
   "metadata": {},
   "source": [
    "Finally, let’s plot the results for cross-validated $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f1de3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r2_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            grid_r2.cv_results_['mean_test_score'],\n",
    "            yerr=grid_r2.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated $R^2$', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6f97b",
   "metadata": {},
   "source": [
    "### Fast Cross-Validation for Solution Paths\n",
    "The ridge, lasso, and elastic net can be efficiently fit along a sequence of $\\lambda$ values, creating what is known as a *solution path* or *regularization path*. Hence there is specialized code to fit\n",
    "such paths, and to choose a suitable value of $\\lambda$ using cross-validation. Even with\n",
    "identical splits the results will not agree *exactly* with our `grid`\n",
    "above because the standardization of each feature  in `grid` is carried out on each fold,\n",
    "while in `pipeCV` below it is carried out only once.\n",
    "Nevertheless, the results are similar as the normalization\n",
    "is relatively stable across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ffe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas, \n",
    "                           l1_ratio=0,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)])\n",
    "pipeCV.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6845efe",
   "metadata": {},
   "source": [
    "Let’s produce a plot again of the cross-validation error to see that\n",
    "it is similar to using `skm.GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_ridge = pipeCV.named_steps['ridge']\n",
    "ridgeCV_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            tuned_ridge.mse_path_.mean(1),\n",
    "            yerr=tuned_ridge.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_ridge.alpha_), c='k', ls='--')\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e07995",
   "metadata": {},
   "source": [
    "We see that the value of $\\lambda$ that results in the\n",
    "smallest cross-validation error is 1.19e-02, available\n",
    "as the value `tuned_ridge.alpha_`. What is the test MSE\n",
    "associated with this value of $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(tuned_ridge.mse_path_.mean(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0961957c",
   "metadata": {},
   "source": [
    "This represents a further improvement over the test MSE that we got\n",
    "using $\\lambda=4$.  Finally, `tuned_ridge.coef_`\n",
    "has the coefficients fit on the entire data set\n",
    "at this value of  $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e7e79",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "tuned_ridge.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ffa3f",
   "metadata": {},
   "source": [
    "As expected, none of the coefficients are zero—ridge regression does\n",
    "not perform variable selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6c72e",
   "metadata": {},
   "source": [
    "### Evaluating Test Error of Cross-Validated Ridge\n",
    "Choosing $\\lambda$ using cross-validation provides a single regression\n",
    "estimator, similar to fitting a linear regression model as we saw in\n",
    "Chapter 3. It is therefore reasonable to estimate what its test error\n",
    "is. We run into a problem here in that cross-validation will have\n",
    "*touched* all of its data in choosing $\\lambda$, hence we have no\n",
    "further data to estimate test error. A compromise is to do an initial\n",
    "split of the data into two disjoint sets: a training set and a test set.\n",
    "We then fit a cross-validation\n",
    "tuned ridge regression on the training set, and evaluate its performance on the test set.\n",
    "We might call this cross-validation nested\n",
    "within the validation set approach. A priori there is no reason to use\n",
    "half of the data for each of the two sets in validation. Below, we use\n",
    "75% for training and 25% for test, with the estimator being ridge\n",
    "regression tuned using 5-fold cross-validation.  This can be achieved\n",
    "in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9140b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_valid = skm.ShuffleSplit(n_splits=1, \n",
    "                               test_size=0.25,\n",
    "                               random_state=1)\n",
    "inner_cv = skm.KFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=2)\n",
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas,\n",
    "                           l1_ratio=0,\n",
    "                           cv=inner_cv)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4aea0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "results = skm.cross_validate(pipeCV, \n",
    "                             X,\n",
    "                             Y,\n",
    "                             cv=outer_valid,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "-results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27147ec",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f126e9",
   "metadata": {},
   "source": [
    "### The Lasso\n",
    "We saw that ridge regression with a wise choice of $\\lambda$ can\n",
    "outperform least squares as well as the null model on the\n",
    " `Hitters`  data set. We now ask whether the lasso can yield\n",
    "either a more accurate or a more interpretable model than ridge\n",
    "regression. In order to fit a lasso model, we once again use the\n",
    "`ElasticNetCV()`  function; however, this time we use the argument\n",
    "`l1_ratio=1`. Other than that change, we proceed just as we did in\n",
    "fitting a ridge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ecc7c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# fit a lasso model as described\n",
    "\n",
    "#lassoCV = skl.ElasticNetCV(...)\n",
    "#pipeCV =  Pipeline(...)\n",
    "pipeCV.fit(X, Y)\n",
    "tuned_lasso = pipeCV.named_steps['lasso']\n",
    "tuned_lasso.alpha_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b909861",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "lambdas, soln_array = skl.Lasso.path(Xs, \n",
    "                                    Y,\n",
    "                                    l1_ratio=1,\n",
    "                                    n_alphas=100)[:2]\n",
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec44b3",
   "metadata": {},
   "source": [
    "We can see from the coefficient plot of the standardized coefficients that depending on the choice of\n",
    "tuning parameter, some of the coefficients will be exactly equal to\n",
    "zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff719798",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "path_fig, ax = subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficiients', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ccdfb",
   "metadata": {},
   "source": [
    "The smallest cross-validated error is lower than the test set MSE of the null model\n",
    "and of least squares, and very similar to the test MSE of 115526.71 of ridge\n",
    "regression (page 278) with $\\lambda$ chosen by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ad8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(tuned_lasso.mse_path_.mean(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f171f",
   "metadata": {},
   "source": [
    "Let’s again produce a plot of the cross-validation error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoCV_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(tuned_lasso.alphas_),\n",
    "            tuned_lasso.mse_path_.mean(1),\n",
    "            yerr=tuned_lasso.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_lasso.alpha_), c='k', ls='--')\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b85ea4",
   "metadata": {},
   "source": [
    "However, the lasso has a substantial advantage over ridge regression\n",
    "in that the resulting coefficient estimates are sparse. Here we see\n",
    "that 6 of the 19 coefficient estimates are exactly zero. So the lasso\n",
    "model with $\\lambda$ chosen by cross-validation contains only 13\n",
    "variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_lasso.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5ed38",
   "metadata": {},
   "source": [
    "As in ridge regression, we could evaluate the test error\n",
    "of cross-validated lasso by first splitting into\n",
    "test and training sets and internally running\n",
    "cross-validation on the training set. We leave\n",
    "this as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0aca26",
   "metadata": {},
   "source": [
    "## PCR and PLS Regression\n",
    "\n",
    "### Principal Components Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2120ab5",
   "metadata": {},
   "source": [
    "Principal components regression (PCR) can be performed using\n",
    "`PCA()`  from the `sklearn.decomposition`\n",
    "module. We now apply PCR to the  `Hitters`  data, in order to\n",
    "predict `Salary`. Again, ensure that the missing values have\n",
    "been removed from the data, as described in Section 6.5.1.\n",
    "\n",
    "We use `LinearRegression()`  to fit the regression model\n",
    "here. Note that it fits an intercept by default, unlike\n",
    "the `OLS()` function seen earlier in Section 6.5.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf302d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "linreg = skl.LinearRegression()\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X, Y)\n",
    "pipe.named_steps['linreg'].coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b909182b",
   "metadata": {},
   "source": [
    "When performing PCA, the results vary depending\n",
    "on whether the data has been *standardized* or not.\n",
    "As in the earlier examples, this can be accomplished\n",
    "by including an additional step in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4145b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', scaler), \n",
    "                 ('pca', pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X, Y)\n",
    "pipe.named_steps['linreg'].coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da4ae12",
   "metadata": {},
   "source": [
    "We can of course use CV to choose the number of components, by\n",
    "using `skm.GridSearchCV`, in this\n",
    "case fixing the parameters to vary the\n",
    "`n_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e047ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'pca__n_components': range(1, 20)}\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bf752",
   "metadata": {},
   "source": [
    "Let’s plot the results as we have for other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_fig, ax = subplots(figsize=(8,8))\n",
    "n_comp = param_grid['pca__n_components']\n",
    "ax.errorbar(n_comp,\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.set_xlabel('# principal components', fontsize=20)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269a0db",
   "metadata": {},
   "source": [
    "We see that the smallest cross-validation error occurs when\n",
    "17\n",
    "components are used. However, from the plot we also see that the\n",
    "cross-validation error is roughly the same when only one component is\n",
    "included in the model. This suggests that a model that uses just a\n",
    "small number of components might suffice.\n",
    "\n",
    "The CV score is provided for each possible number of components from\n",
    "1 to 19 inclusive. The `PCA()` method complains\n",
    "if we try to fit an intercept only with `n_components=0`\n",
    "so we also compute the MSE for just the null model with\n",
    "these splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e084cbb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Xn = np.zeros((X.shape[0], 1))\n",
    "cv_null = skm.cross_validate(linreg,\n",
    "                             Xn,\n",
    "                             Y,\n",
    "                             cv=kfold,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "-cv_null['test_score'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d69df",
   "metadata": {},
   "source": [
    "The `explained_variance_ratio_`\n",
    "attribute of our `PCA` object provides the *percentage of variance explained* in the predictors and in the response using\n",
    "different numbers of components. This concept is discussed in greater\n",
    "detail in Section 12.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7616c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['pca'].explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee7cb1",
   "metadata": {},
   "source": [
    "Briefly, we can think of\n",
    "this as the amount of information about the predictors\n",
    "that is captured using $M$ principal components. For example, setting\n",
    "$M=1$ only captures 38.31% of the variance, while $M=2$ captures an additional 21.84%, for a total of 60.15% of the variance.\n",
    "By  $M=6$ it increases to\n",
    "88.63%. Beyond this the increments continue to diminish, until we use all $M=p=19$ components, which captures all  100% of the variance.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ce7e4",
   "metadata": {},
   "source": [
    "### Partial Least Squares\n",
    "Partial least squares (PLS) is implemented in the\n",
    "`PLSRegression()`  function.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=2, \n",
    "                    scale=True)\n",
    "pls.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00592ba",
   "metadata": {},
   "source": [
    "As was the case in PCR, we will want to\n",
    "use CV to choose the number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_components':range(1, 20)}\n",
    "grid = skm.GridSearchCV(pls,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc745c",
   "metadata": {},
   "source": [
    "As for our other methods, we plot the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_fig, ax = subplots(figsize=(8,8))\n",
    "n_comp = param_grid['n_components']\n",
    "ax.errorbar(n_comp,\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.set_xlabel('# principal components', fontsize=20)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ec466",
   "metadata": {},
   "source": [
    "CV error is minimized at 12,\n",
    "though there is little noticeable difference between this point and a much lower number like 2 or 3 components.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,Rmd",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "mxn442_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
